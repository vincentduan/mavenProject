2017-11-24 16:23:36.990 [main] DEBUG org.springframework.test.context.junit4.SpringJUnit4ClassRunner - SpringJUnit4ClassRunner constructor called with [class ExtractTest]
2017-11-24 16:23:36.994 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating CacheAwareContextLoaderDelegate from class [org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate]
2017-11-24 16:23:37.000 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating BootstrapContext using constructor [public org.springframework.test.context.support.DefaultBootstrapContext(java.lang.Class,org.springframework.test.context.CacheAwareContextLoaderDelegate)]
2017-11-24 16:23:37.006 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating TestContextBootstrapper for test class [ExtractTest] from class [org.springframework.test.context.support.DefaultTestContextBootstrapper]
2017-11-24 16:23:37.029 [main] DEBUG org.springframework.test.context.support.AbstractDelegatingSmartContextLoader - Delegating to GenericXmlContextLoader to process context configuration [ContextConfigurationAttributes@22eeefeb declaringClass = 'ExtractTest', classes = '{}', locations = '{classpath*:spring/*.xml}', inheritLocations = true, initializers = '{}', inheritInitializers = true, name = [null], contextLoaderClass = 'org.springframework.test.context.ContextLoader'].
2017-11-24 16:23:37.051 [main] DEBUG org.springframework.test.context.support.ActiveProfilesUtils - Could not find an 'annotation declaring class' for annotation type [org.springframework.test.context.ActiveProfiles] and class [ExtractTest]
2017-11-24 16:23:37.053 [main] DEBUG org.springframework.test.context.support.DefaultTestContextBootstrapper - @TestExecutionListeners is not present for class [ExtractTest]: using defaults.
2017-11-24 16:23:37.054 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-24 16:23:37.057 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-24 16:23:37.067 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-24 16:23:37.068 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [ExtractTest]
2017-11-24 16:23:37.068 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [ExtractTest]
2017-11-24 16:23:37.069 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [ExtractTest]
2017-11-24 16:23:37.069 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [ExtractTest]
2017-11-24 16:23:37.072 [main] DEBUG o.s.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test class: context [DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null].
2017-11-24 16:23:37.073 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [ExtractTest]
2017-11-24 16:23:37.074 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [ExtractTest]
2017-11-24 16:23:37.075 [main] DEBUG o.springframework.test.context.support.DependencyInjectionTestExecutionListener - Performing dependency injection for test context [[DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@11c20519, testMethod = [null], testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]]].
2017-11-24 16:23:37.076 [main] DEBUG org.springframework.test.context.support.AbstractDelegatingSmartContextLoader - Delegating to GenericXmlContextLoader to load context from [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]].
2017-11-24 16:23:37.076 [main] DEBUG org.springframework.test.context.support.AbstractGenericContextLoader - Loading ApplicationContext for merged context configuration [[MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]]].
2017-11-24 16:23:37.110 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemProperties' with lowest search precedence
2017-11-24 16:23:37.112 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemEnvironment' with lowest search precedence
2017-11-24 16:23:37.112 [main] DEBUG org.springframework.core.env.StandardEnvironment - Initialized StandardEnvironment with PropertySources [MapPropertySource@380242442 {name='systemProperties', properties={idea.version=2017.2.6, java.runtime.name=Java(TM) SE Runtime Environment, sun.boot.library.path=E:\Program Files\Java\jdk1.8.0_40\jre\bin, java.vm.version=25.40-b25, java.vm.vendor=Oracle Corporation, java.vendor.url=http://java.oracle.com/, path.separator=;, java.vm.name=Java HotSpot(TM) 64-Bit Server VM, file.encoding.pkg=sun.io, user.country=CN, user.script=, sun.java.launcher=SUN_STANDARD, sun.os.patch.level=, java.vm.specification.name=Java Virtual Machine Specification, user.dir=F:\git\mavenProject\file2DB\file2DB-service, java.runtime.version=1.8.0_40-b25, basedir=F:\git\mavenProject\file2DB\file2DB-service, java.awt.graphicsenv=sun.awt.Win32GraphicsEnvironment, java.endorsed.dirs=E:\Program Files\Java\jdk1.8.0_40\jre\lib\endorsed, os.arch=amd64, surefire.real.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefirebooter2477867052819822086.jar, java.io.tmpdir=C:\Users\vincent\AppData\Local\Temp\, line.separator=
, java.vm.specification.vendor=Oracle Corporation, user.variant=, os.name=Windows 8.1, sun.jnu.encoding=GBK, java.library.path=E:\Program Files\Java\jdk1.8.0_40\jre\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;E:\Program Files\Java\jdk1.8.0_40\bin;C:\Program Files (x86)\Common Files\NetSarang;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;E:\java\apache-maven-3.3.3\bin;E:\java\mysql-5.7.13-winx64\bin;E:\Program Files\MATLAB\R2012a\runtime\win64;E:\Program Files\MATLAB\R2012a\bin;E:\Users\vincent\AppData\Local\Android\sdk\platform-tools;F:\git\node-v6.11.4-win-x64;E:\Program Files\Git\bin;C:\Users\vincent\AppData\Local\Microsoft\WindowsApps;;., surefire.test.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\test-classes;F:\git\mavenProject\file2DB\file2DB-service\target\classes;F:\git\mavenProject\file2DB\file2DB-common\target\file2DB-common-1.0-SNAPSHOT.jar;E:\java\repository\org\springframework\kafka\spring-kafka\2.0.0.RELEASE\spring-kafka-2.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-context\5.0.0.RELEASE\spring-context-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-aop\5.0.0.RELEASE\spring-aop-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-expression\5.0.0.RELEASE\spring-expression-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-messaging\5.0.0.RELEASE\spring-messaging-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-tx\5.0.0.RELEASE\spring-tx-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\retry\spring-retry\1.2.0.RELEASE\spring-retry-1.2.0.RELEASE.jar;E:\java\repository\org\apache\kafka\kafka-clients\0.11.0.0\kafka-clients-0.11.0.0.jar;E:\java\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;E:\java\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;E:\java\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;E:\java\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\java\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\java\repository\junit\junit\4.12\junit-4.12.jar;E:\java\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;E:\java\repository\org\springframework\spring-test\5.0.0.RELEASE\spring-test-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-core\5.0.0.RELEASE\spring-core-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jcl\5.0.0.RELEASE\spring-jcl-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jdbc\5.0.0.RELEASE\spring-jdbc-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-beans\5.0.0.RELEASE\spring-beans-5.0.0.RELEASE.jar;E:\java\repository\org\mybatis\mybatis\3.4.5\mybatis-3.4.5.jar;E:\java\repository\org\mybatis\mybatis-spring\1.3.1\mybatis-spring-1.3.1.jar;E:\java\repository\mysql\mysql-connector-java\5.1.44\mysql-connector-java-5.1.44.jar;E:\java\repository\c3p0\c3p0\0.9.1.2\c3p0-0.9.1.2.jar;E:\java\repository\commons-io\commons-io\2.6\commons-io-2.6.jar;E:\java\repository\joda-time\joda-time\2.9.9\joda-time-2.9.9.jar;, java.specification.name=Java Platform API Specification, java.class.version=52.0, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, maven.repo.local=E:\java\repository, os.version=6.3, user.home=C:\Users\vincent, user.timezone=Asia/Shanghai, java.awt.printerjob=sun.awt.windows.WPrinterJob, file.encoding=GBK, java.specification.version=1.8, java.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\test-classes;F:\git\mavenProject\file2DB\file2DB-service\target\classes;F:\git\mavenProject\file2DB\file2DB-common\target\file2DB-common-1.0-SNAPSHOT.jar;E:\java\repository\org\springframework\kafka\spring-kafka\2.0.0.RELEASE\spring-kafka-2.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-context\5.0.0.RELEASE\spring-context-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-aop\5.0.0.RELEASE\spring-aop-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-expression\5.0.0.RELEASE\spring-expression-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-messaging\5.0.0.RELEASE\spring-messaging-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-tx\5.0.0.RELEASE\spring-tx-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\retry\spring-retry\1.2.0.RELEASE\spring-retry-1.2.0.RELEASE.jar;E:\java\repository\org\apache\kafka\kafka-clients\0.11.0.0\kafka-clients-0.11.0.0.jar;E:\java\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;E:\java\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;E:\java\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;E:\java\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\java\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\java\repository\junit\junit\4.12\junit-4.12.jar;E:\java\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;E:\java\repository\org\springframework\spring-test\5.0.0.RELEASE\spring-test-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-core\5.0.0.RELEASE\spring-core-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jcl\5.0.0.RELEASE\spring-jcl-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jdbc\5.0.0.RELEASE\spring-jdbc-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-beans\5.0.0.RELEASE\spring-beans-5.0.0.RELEASE.jar;E:\java\repository\org\mybatis\mybatis\3.4.5\mybatis-3.4.5.jar;E:\java\repository\org\mybatis\mybatis-spring\1.3.1\mybatis-spring-1.3.1.jar;E:\java\repository\mysql\mysql-connector-java\5.1.44\mysql-connector-java-5.1.44.jar;E:\java\repository\c3p0\c3p0\0.9.1.2\c3p0-0.9.1.2.jar;E:\java\repository\commons-io\commons-io\2.6\commons-io-2.6.jar;E:\java\repository\joda-time\joda-time\2.9.9\joda-time-2.9.9.jar;, user.name=vincent, java.vm.specification.version=1.8, sun.java.command=F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefirebooter2477867052819822086.jar F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefire7735783549134567590tmp F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefire_08912352951682761711tmp, java.home=E:\Program Files\Java\jdk1.8.0_40\jre, sun.arch.data.model=64, user.language=zh, java.specification.vendor=Oracle Corporation, awt.toolkit=sun.awt.windows.WToolkit, java.vm.info=mixed mode, java.version=1.8.0_40, java.ext.dirs=E:\Program Files\Java\jdk1.8.0_40\jre\lib\ext;C:\WINDOWS\Sun\Java\lib\ext, sun.boot.class.path=E:\Program Files\Java\jdk1.8.0_40\jre\lib\resources.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\rt.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\sunrsasign.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jsse.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jce.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\charsets.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jfr.jar;E:\Program Files\Java\jdk1.8.0_40\jre\classes, java.vendor=Oracle Corporation, localRepository=E:\java\repository, file.separator=\, java.vendor.url.bug=http://bugreport.sun.com/bugreport/, sun.io.unicode.encoding=UnicodeLittle, sun.cpu.endian=little, sun.desktop=windows, sun.cpu.isalist=amd64}}, SystemEnvironmentPropertySource@125881207 {name='systemEnvironment', properties={PATH=E:\Program Files\Java\jdk1.8.0_40\bin;C:\Program Files (x86)\Common Files\NetSarang;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;E:\java\apache-maven-3.3.3\bin;E:\java\mysql-5.7.13-winx64\bin;E:\Program Files\MATLAB\R2012a\runtime\win64;E:\Program Files\MATLAB\R2012a\bin;E:\Users\vincent\AppData\Local\Android\sdk\platform-tools;F:\git\node-v6.11.4-win-x64;E:\Program Files\Git\bin;C:\Users\vincent\AppData\Local\Microsoft\WindowsApps;, USERDOMAIN_ROAMINGPROFILE=DESKTOP-8IAUFDG, GIT_HOME=E:\Program Files\Git, LOCALAPPDATA=C:\Users\vincent\AppData\Local, PROCESSOR_LEVEL=6, SYSTEMDRIVE=C:, COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files, USERDOMAIN=DESKTOP-8IAUFDG, FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer, LOGONSERVER=\\DESKTOP-8IAUFDG, JAVA_HOME=E:\Program Files\Java\jdk1.8.0_40, PROMPT=$P$G, SESSIONNAME=Console, ALLUSERSPROFILE=C:\ProgramData, PROGRAMFILES(X86)=C:\Program Files (x86), PROCESSOR_ARCHITECTURE=AMD64, MAVEN_HOME=E:\java\apache-maven-3.3.3, PROGRAMFILES=C:\Program Files, APPDATA=C:\Users\vincent\AppData\Roaming, PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files\Intel\, PROGRAMW6432=C:\Program Files, PROGRAMDATA=C:\ProgramData, SYSTEMROOT=C:\WINDOWS, USERNAME=vincent, FPS_BROWSER_USER_PROFILE_STRING=Default, ONEDRIVE=C:\Users\vincent\OneDrive, PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC, OS=Windows_NT, COMMONPROGRAMW6432=C:\Program Files\Common Files, COMPUTERNAME=DESKTOP-8IAUFDG, COMMONPROGRAMFILES=C:\Program Files\Common Files, COMSPEC=C:\WINDOWS\system32\cmd.exe, JAVA_HOME_X86=C:\ProgramData\Oracle\Java\javapath, PROCESSOR_REVISION=3c03, CLASSPATH=.;F:\git\jade\JADE-bin-4.5.0\jade\lib\jade.jar;, WINDIR=C:\WINDOWS, =F:=F:\git\mavenProject\file2DB\file2DB-service, HOMEPATH=\Users\vincent, TEMP=C:\Users\vincent\AppData\Local\Temp, HOMEDRIVE=C:, PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 60 Stepping 3, GenuineIntel, USERPROFILE=C:\Users\vincent, TMP=C:\Users\vincent\AppData\Local\Temp, PUBLIC=C:\Users\Public, NUMBER_OF_PROCESSORS=4}}]
2017-11-24 16:23:37.118 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved classpath location [spring/] to resources [URL [file:/F:/git/mavenProject/file2DB/file2DB-service/target/classes/spring/]]
2017-11-24 16:23:37.119 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring]
2017-11-24 16:23:37.119 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring] for files matching pattern [F:/git/mavenProject/file2DB/file2DB-service/target/classes/spring/*.xml]
2017-11-24 16:23:37.121 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath*:spring/*.xml] to resources [file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml], file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml], file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml], file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]]
2017-11-24 16:23:37.123 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-24 16:23:37.135 [main] DEBUG org.springframework.beans.factory.xml.DefaultDocumentLoader - Using JAXP provider [com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl]
2017-11-24 16:23:37.157 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Loading schema mappings from [META-INF/spring.schemas]
2017-11-24 16:23:37.159 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Loaded schema mappings: {http://www.springframework.org/schema/tx/spring-tx-2.5.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/tx/spring-tx-4.3.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/cache/spring-cache-4.2.xsd=org/springframework/cache/config/spring-cache.xsd, http://www.springframework.org/schema/aop/spring-aop-4.1.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/context/spring-context-3.1.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/jdbc/spring-jdbc-4.1.xsd=org/springframework/jdbc/config/spring-jdbc.xsd, http://www.springframework.org/schema/util/spring-util-3.0.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://mybatis.org/schema/mybatis-spring-1.2.xsd=org/mybatis/spring/config/mybatis-spring-1.2.xsd, http://www.springframework.org/schema/tool/spring-tool.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/aop/spring-aop-3.2.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/lang/spring-lang-4.1.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/context/spring-context-4.0.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/beans/spring-beans-4.2.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/tool/spring-tool-4.1.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/lang/spring-lang-3.2.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/cache/spring-cache-3.2.xsd=org/springframework/cache/config/spring-cache.xsd, http://www.springframework.org/schema/jee/spring-jee-4.1.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/jdbc/spring-jdbc-3.1.xsd=org/springframework/jdbc/config/spring-jdbc.xsd, http://www.springframework.org/schema/util/spring-util-2.0.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/task/spring-task-4.2.xsd=org/springframework/scheduling/config/spring-task.xsd, http://www.springframework.org/schema/tool/spring-tool-3.2.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/context/spring-context.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/tx/spring-tx-4.2.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/cache/spring-cache-4.1.xsd=org/springframework/cache/config/spring-cache.xsd, http://www.springframework.org/schema/aop/spring-aop-4.0.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/jee/spring-jee-3.2.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/context/spring-context-3.0.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/jdbc/spring-jdbc-4.0.xsd=org/springframework/jdbc/config/spring-jdbc.xsd, http://www.springframework.org/schema/util/spring-util-4.3.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/util/spring-util-2.5.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/beans/spring-beans-3.2.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/aop/spring-aop-3.1.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/lang/spring-lang-4.0.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/beans/spring-beans-4.1.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/tool/spring-tool-4.0.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/lang/spring-lang-3.1.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/tx/spring-tx-3.2.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/cache/spring-cache-3.1.xsd=org/springframework/cache/config/spring-cache.xsd, http://www.springframework.org/schema/jee/spring-jee-4.0.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/jdbc/spring-jdbc-3.0.xsd=org/springframework/jdbc/config/spring-jdbc.xsd, http://www.springframework.org/schema/task/spring-task-4.1.xsd=org/springframework/scheduling/config/spring-task.xsd, http://www.springframework.org/schema/tool/spring-tool-3.1.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/jdbc/spring-jdbc.xsd=org/springframework/jdbc/config/spring-jdbc.xsd, http://www.springframework.org/schema/tx/spring-tx-4.1.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/cache/spring-cache-4.0.xsd=org/springframework/cache/config/spring-cache.xsd, http://www.springframework.org/schema/jee/spring-jee-3.1.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/util/spring-util-4.2.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/task/spring-task-3.2.xsd=org/springframework/scheduling/config/spring-task.xsd, http://www.springframework.org/schema/beans/spring-beans-3.1.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/util/spring-util.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/aop/spring-aop-3.0.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/beans/spring-beans-4.0.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/beans/spring-beans.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://mybatis.org/schema/mybatis-spring.xsd=org/mybatis/spring/config/mybatis-spring-1.2.xsd, http://www.springframework.org/schema/lang/spring-lang-3.0.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/tx/spring-tx-3.1.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/context/spring-context-2.5.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/context/spring-context-4.3.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/task/spring-task-4.0.xsd=org/springframework/scheduling/config/spring-task.xsd, http://www.springframework.org/schema/tool/spring-tool-3.0.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/tx/spring-tx-4.0.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/aop/spring-aop-2.0.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/jee/spring-jee-3.0.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/util/spring-util-4.1.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/task/spring-task-3.1.xsd=org/springframework/scheduling/config/spring-task.xsd, http://www.springframework.org/schema/beans/spring-beans-3.0.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/jee/spring-jee.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/aop/spring-aop-2.5.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/aop/spring-aop-4.3.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/lang/spring-lang-2.0.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/jdbc/spring-jdbc-4.3.xsd=org/springframework/jdbc/config/spring-jdbc.xsd, http://www.springframework.org/schema/util/spring-util-3.2.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/task/spring-task.xsd=org/springframework/scheduling/config/spring-task.xsd, http://www.springframework.org/schema/tool/spring-tool-2.0.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/tx/spring-tx-3.0.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/lang/spring-lang-2.5.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/lang/spring-lang-4.3.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/context/spring-context-4.2.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/jee/spring-jee-2.0.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/tool/spring-tool-4.3.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/tool/spring-tool-2.5.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/jee/spring-jee-4.3.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/jee/spring-jee-2.5.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/util/spring-util-4.0.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/task/spring-task-3.0.xsd=org/springframework/scheduling/config/spring-task.xsd, http://www.springframework.org/schema/cache/spring-cache-4.3.xsd=org/springframework/cache/config/spring-cache.xsd, http://www.springframework.org/schema/aop/spring-aop-4.2.xsd=org/springframework/aop/config/spring-aop.xsd, http://www.springframework.org/schema/lang/spring-lang.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/context/spring-context-3.2.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/jdbc/spring-jdbc-4.2.xsd=org/springframework/jdbc/config/spring-jdbc.xsd, http://www.springframework.org/schema/util/spring-util-3.1.xsd=org/springframework/beans/factory/xml/spring-util.xsd, http://www.springframework.org/schema/beans/spring-beans-2.0.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/cache/spring-cache.xsd=org/springframework/cache/config/spring-cache.xsd, http://www.springframework.org/schema/tx/spring-tx.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/lang/spring-lang-4.2.xsd=org/springframework/scripting/config/spring-lang.xsd, http://www.springframework.org/schema/context/spring-context-4.1.xsd=org/springframework/context/config/spring-context.xsd, http://www.springframework.org/schema/beans/spring-beans-4.3.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/beans/spring-beans-2.5.xsd=org/springframework/beans/factory/xml/spring-beans.xsd, http://www.springframework.org/schema/tool/spring-tool-4.2.xsd=org/springframework/beans/factory/xml/spring-tool.xsd, http://www.springframework.org/schema/tx/spring-tx-2.0.xsd=org/springframework/transaction/config/spring-tx.xsd, http://www.springframework.org/schema/jee/spring-jee-4.2.xsd=org/springframework/ejb/config/spring-jee.xsd, http://www.springframework.org/schema/jdbc/spring-jdbc-3.2.xsd=org/springframework/jdbc/config/spring-jdbc.xsd, http://www.springframework.org/schema/task/spring-task-4.3.xsd=org/springframework/scheduling/config/spring-task.xsd, http://www.springframework.org/schema/aop/spring-aop.xsd=org/springframework/aop/config/spring-aop.xsd}
2017-11-24 16:23:37.161 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/beans/spring-beans.xsd] in classpath: org/springframework/beans/factory/xml/spring-beans.xsd
2017-11-24 16:23:37.190 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/context/spring-context-4.3.xsd] in classpath: org/springframework/context/config/spring-context.xsd
2017-11-24 16:23:37.197 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/tool/spring-tool.xsd] in classpath: org/springframework/beans/factory/xml/spring-tool.xsd
2017-11-24 16:23:37.204 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Loading bean definitions
2017-11-24 16:23:37.212 [main] DEBUG org.springframework.beans.factory.xml.DefaultNamespaceHandlerResolver - Loaded NamespaceHandler mappings: {http://www.springframework.org/schema/p=org.springframework.beans.factory.xml.SimplePropertyNamespaceHandler, http://www.springframework.org/schema/util=org.springframework.beans.factory.xml.UtilNamespaceHandler, http://www.springframework.org/schema/jee=org.springframework.ejb.config.JeeNamespaceHandler, http://www.springframework.org/schema/aop=org.springframework.aop.config.AopNamespaceHandler, http://www.springframework.org/schema/jdbc=org.springframework.jdbc.config.JdbcNamespaceHandler, http://www.springframework.org/schema/cache=org.springframework.cache.config.CacheNamespaceHandler, http://mybatis.org/schema/mybatis-spring=org.mybatis.spring.config.NamespaceHandler, http://www.springframework.org/schema/c=org.springframework.beans.factory.xml.SimpleConstructorNamespaceHandler, http://www.springframework.org/schema/tx=org.springframework.transaction.config.TxNamespaceHandler, http://www.springframework.org/schema/task=org.springframework.scheduling.config.TaskNamespaceHandler, http://www.springframework.org/schema/lang=org.springframework.scripting.config.LangNamespaceHandler, http://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler}
2017-11-24 16:23:37.229 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved classpath location [org/service/] to resources [URL [file:/F:/git/mavenProject/file2DB/file2DB-service/target/classes/org/service/]]
2017-11-24 16:23:37.229 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\service]
2017-11-24 16:23:37.229 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\service] for files matching pattern [F:/git/mavenProject/file2DB/file2DB-service/target/classes/org/service/**/*.class]
2017-11-24 16:23:37.230 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\service\impl] for files matching pattern [F:/git/mavenProject/file2DB/file2DB-service/target/classes/org/service/**/*.class]
2017-11-24 16:23:37.230 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath*:org/service/**/*.class] to resources [file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\service\ExtractService.class], file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\service\impl\ExtractServiceImpl.class]]
2017-11-24 16:23:37.247 [main] DEBUG org.springframework.context.annotation.ClassPathBeanDefinitionScanner - Identified candidate component class: file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\service\impl\ExtractServiceImpl.class]
2017-11-24 16:23:37.263 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 16:23:37.264 [main] DEBUG org.springframework.beans.factory.xml.DefaultDocumentLoader - Using JAXP provider [com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl]
2017-11-24 16:23:37.265 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/beans/spring-beans.xsd] in classpath: org/springframework/beans/factory/xml/spring-beans.xsd
2017-11-24 16:23:37.277 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Loading bean definitions
2017-11-24 16:23:37.279 [main] DEBUG org.springframework.beans.factory.xml.BeanDefinitionParserDelegate - Neither XML 'id' nor 'name' specified - using generated bean name [org.mybatis.spring.mapper.MapperScannerConfigurer#0]
2017-11-24 16:23:37.279 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Imported 3 bean definitions from relative location [spring-dao.xml]
2017-11-24 16:23:37.280 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 16:23:37.281 [main] DEBUG org.springframework.beans.factory.xml.DefaultDocumentLoader - Using JAXP provider [com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl]
2017-11-24 16:23:37.282 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/beans/spring-beans.xsd] in classpath: org/springframework/beans/factory/xml/spring-beans.xsd
2017-11-24 16:23:37.305 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Loading bean definitions
2017-11-24 16:23:37.315 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Imported 81 bean definitions from relative location [spring-consumer.xml]
2017-11-24 16:23:37.317 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 16:23:37.318 [main] DEBUG org.springframework.beans.factory.xml.DefaultDocumentLoader - Using JAXP provider [com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl]
2017-11-24 16:23:37.319 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/beans/spring-beans.xsd] in classpath: org/springframework/beans/factory/xml/spring-beans.xsd
2017-11-24 16:23:37.326 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Loading bean definitions
2017-11-24 16:23:37.327 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Imported 3 bean definitions from relative location [spring-producer.xml]
2017-11-24 16:23:37.327 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 16:23:37.329 [main] DEBUG org.springframework.beans.factory.xml.DefaultDocumentLoader - Using JAXP provider [com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl]
2017-11-24 16:23:37.331 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/beans/spring-beans.xsd] in classpath: org/springframework/beans/factory/xml/spring-beans.xsd
2017-11-24 16:23:37.347 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Loading bean definitions
2017-11-24 16:23:37.348 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumer1' with an equivalent definition: replacing [Generic bean: class [java.util.HashMap]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [java.util.HashMap]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.349 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory1' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.350 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory2' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.350 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory3' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.350 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory4' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.350 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory5' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.351 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory6' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.351 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory7' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.351 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory8' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.351 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory9' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory10' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory11' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory12' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory13' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.353 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory14' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.353 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory15' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.353 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory16' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.353 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory17' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.354 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory18' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.354 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory19' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.354 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'consumerFactory20' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaConsumerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.354 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.354 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService2' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener2]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener2]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.355 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService3' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener3]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener3]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.355 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService4' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener4]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener4]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.355 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService5' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener5]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener5]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.355 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService6' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener6]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener6]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.355 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService7' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener7]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener7]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.355 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService8' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener8]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener8]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.355 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService9' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener9]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener9]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.356 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService10' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener10]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener10]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.356 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService11' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener11]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener11]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.356 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService12' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener12]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener12]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.356 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService13' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener13]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener13]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.356 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService14' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener14]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener14]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService15' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener15]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener15]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService16' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener16]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener16]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService17' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener17]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener17]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService18' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener18]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener18]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.358 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService19' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener19]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener19]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.358 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListernerConsumerService20' with an equivalent definition: replacing [Generic bean: class [org.taian.KafkaConsumerListener20]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.taian.KafkaConsumerListener20]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.358 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties1' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.358 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties2' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.359 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties3' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.359 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties4' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.359 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties5' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.359 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties6' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.360 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties7' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.361 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties8' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.361 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties9' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties10' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties11' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties12' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties13' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.363 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties14' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.363 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties15' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.363 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties16' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.363 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties17' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.364 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties18' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.364 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties19' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.364 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'containerProperties20' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.config.ContainerProperties]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.364 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.365 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer2' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.365 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer3' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.365 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer4' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.365 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer5' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.365 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer6' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.366 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer7' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.366 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer8' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.366 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer9' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.367 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer10' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.367 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer11' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.367 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer12' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.367 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer13' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.367 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer14' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.368 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer15' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.368 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer16' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.368 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer17' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.368 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer18' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.368 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer19' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.369 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'messageListenerContainer20' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]] with [Generic bean: class [org.springframework.kafka.listener.KafkaMessageListenerContainer]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=doStart; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]]
2017-11-24 16:23:37.369 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 16:23:37.370 [main] DEBUG org.springframework.beans.factory.xml.DefaultDocumentLoader - Using JAXP provider [com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl]
2017-11-24 16:23:37.372 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/beans/spring-beans.xsd] in classpath: org/springframework/beans/factory/xml/spring-beans.xsd
2017-11-24 16:23:37.381 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Loading bean definitions
2017-11-24 16:23:37.382 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'dataSource' with an equivalent definition: replacing [Generic bean: class [com.mchange.v2.c3p0.ComboPooledDataSource]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]] with [Generic bean: class [com.mchange.v2.c3p0.ComboPooledDataSource]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]]
2017-11-24 16:23:37.382 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'sqlSessionFactory' with an equivalent definition: replacing [Generic bean: class [org.mybatis.spring.SqlSessionFactoryBean]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]] with [Generic bean: class [org.mybatis.spring.SqlSessionFactoryBean]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]]
2017-11-24 16:23:37.383 [main] DEBUG org.springframework.beans.factory.xml.BeanDefinitionParserDelegate - Neither XML 'id' nor 'name' specified - using generated bean name [org.mybatis.spring.mapper.MapperScannerConfigurer#1]
2017-11-24 16:23:37.383 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 16:23:37.384 [main] DEBUG org.springframework.beans.factory.xml.DefaultDocumentLoader - Using JAXP provider [com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl]
2017-11-24 16:23:37.385 [main] DEBUG org.springframework.beans.factory.xml.PluggableSchemaResolver - Found XML schema [http://www.springframework.org/schema/beans/spring-beans.xsd] in classpath: org/springframework/beans/factory/xml/spring-beans.xsd
2017-11-24 16:23:37.393 [main] DEBUG org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader - Loading bean definitions
2017-11-24 16:23:37.394 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'producerProperties' with an equivalent definition: replacing [Generic bean: class [java.util.HashMap]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]] with [Generic bean: class [java.util.HashMap]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]]
2017-11-24 16:23:37.394 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'producerFactory' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.DefaultKafkaProducerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]] with [Generic bean: class [org.springframework.kafka.core.DefaultKafkaProducerFactory]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]]
2017-11-24 16:23:37.394 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'KafkaTemplate' with an equivalent definition: replacing [Generic bean: class [org.springframework.kafka.core.KafkaTemplate]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]] with [Generic bean: class [org.springframework.kafka.core.KafkaTemplate]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]]
2017-11-24 16:23:37.394 [main] DEBUG org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loaded 97 bean definitions from location pattern [classpath*:spring/*.xml]
2017-11-24 16:23:37.398 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 16:23:37 CST 2017]; root of context hierarchy
2017-11-24 16:23:37.398 [main] DEBUG org.springframework.context.support.GenericApplicationContext - Bean factory for org.springframework.context.support.GenericApplicationContext@3c0a50da: org.springframework.beans.factory.support.DefaultListableBeanFactory@694abbdc: defining beans [extractServiceImpl,org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,propertyConfigurer,transactionManager,dataSource,sqlSessionFactory,org.mybatis.spring.mapper.MapperScannerConfigurer#0,consumer1,consumerFactory1,consumerFactory2,consumerFactory3,consumerFactory4,consumerFactory5,consumerFactory6,consumerFactory7,consumerFactory8,consumerFactory9,consumerFactory10,consumerFactory11,consumerFactory12,consumerFactory13,consumerFactory14,consumerFactory15,consumerFactory16,consumerFactory17,consumerFactory18,consumerFactory19,consumerFactory20,messageListernerConsumerService,messageListernerConsumerService2,messageListernerConsumerService3,messageListernerConsumerService4,messageListernerConsumerService5,messageListernerConsumerService6,messageListernerConsumerService7,messageListernerConsumerService8,messageListernerConsumerService9,messageListernerConsumerService10,messageListernerConsumerService11,messageListernerConsumerService12,messageListernerConsumerService13,messageListernerConsumerService14,messageListernerConsumerService15,messageListernerConsumerService16,messageListernerConsumerService17,messageListernerConsumerService18,messageListernerConsumerService19,messageListernerConsumerService20,containerProperties1,containerProperties2,containerProperties3,containerProperties4,containerProperties5,containerProperties6,containerProperties7,containerProperties8,containerProperties9,containerProperties10,containerProperties11,containerProperties12,containerProperties13,containerProperties14,containerProperties15,containerProperties16,containerProperties17,containerProperties18,containerProperties19,containerProperties20,messageListenerContainer,messageListenerContainer2,messageListenerContainer3,messageListenerContainer4,messageListenerContainer5,messageListenerContainer6,messageListenerContainer7,messageListenerContainer8,messageListenerContainer9,messageListenerContainer10,messageListenerContainer11,messageListenerContainer12,messageListenerContainer13,messageListenerContainer14,messageListenerContainer15,messageListenerContainer16,messageListenerContainer17,messageListenerContainer18,messageListenerContainer19,messageListenerContainer20,producerProperties,producerFactory,KafkaTemplate,org.mybatis.spring.mapper.MapperScannerConfigurer#1]; root of factory hierarchy
2017-11-24 16:23:37.442 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
2017-11-24 16:23:37.442 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
2017-11-24 16:23:37.454 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor' to allow for resolving potential circular references
2017-11-24 16:23:37.455 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
2017-11-24 16:23:37.513 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#0'
2017-11-24 16:23:37.514 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#0'
2017-11-24 16:23:37.514 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#0' to allow for resolving potential circular references
2017-11-24 16:23:37.544 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking afterPropertiesSet() on bean with name 'org.mybatis.spring.mapper.MapperScannerConfigurer#0'
2017-11-24 16:23:37.544 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#0'
2017-11-24 16:23:37.545 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemProperties' with lowest search precedence
2017-11-24 16:23:37.545 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemEnvironment' with lowest search precedence
2017-11-24 16:23:37.545 [main] DEBUG org.springframework.core.env.StandardEnvironment - Initialized StandardEnvironment with PropertySources [MapPropertySource@640113647 {name='systemProperties', properties={idea.version=2017.2.6, java.runtime.name=Java(TM) SE Runtime Environment, sun.boot.library.path=E:\Program Files\Java\jdk1.8.0_40\jre\bin, java.vm.version=25.40-b25, java.vm.vendor=Oracle Corporation, java.vendor.url=http://java.oracle.com/, path.separator=;, java.vm.name=Java HotSpot(TM) 64-Bit Server VM, file.encoding.pkg=sun.io, user.country=CN, user.script=, sun.java.launcher=SUN_STANDARD, sun.os.patch.level=, java.vm.specification.name=Java Virtual Machine Specification, user.dir=F:\git\mavenProject\file2DB\file2DB-service, java.runtime.version=1.8.0_40-b25, basedir=F:\git\mavenProject\file2DB\file2DB-service, java.awt.graphicsenv=sun.awt.Win32GraphicsEnvironment, java.endorsed.dirs=E:\Program Files\Java\jdk1.8.0_40\jre\lib\endorsed, os.arch=amd64, surefire.real.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefirebooter2477867052819822086.jar, java.io.tmpdir=C:\Users\vincent\AppData\Local\Temp\, line.separator=
, java.vm.specification.vendor=Oracle Corporation, user.variant=, os.name=Windows 8.1, sun.jnu.encoding=GBK, java.library.path=E:\Program Files\Java\jdk1.8.0_40\jre\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;E:\Program Files\Java\jdk1.8.0_40\bin;C:\Program Files (x86)\Common Files\NetSarang;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;E:\java\apache-maven-3.3.3\bin;E:\java\mysql-5.7.13-winx64\bin;E:\Program Files\MATLAB\R2012a\runtime\win64;E:\Program Files\MATLAB\R2012a\bin;E:\Users\vincent\AppData\Local\Android\sdk\platform-tools;F:\git\node-v6.11.4-win-x64;E:\Program Files\Git\bin;C:\Users\vincent\AppData\Local\Microsoft\WindowsApps;;., surefire.test.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\test-classes;F:\git\mavenProject\file2DB\file2DB-service\target\classes;F:\git\mavenProject\file2DB\file2DB-common\target\file2DB-common-1.0-SNAPSHOT.jar;E:\java\repository\org\springframework\kafka\spring-kafka\2.0.0.RELEASE\spring-kafka-2.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-context\5.0.0.RELEASE\spring-context-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-aop\5.0.0.RELEASE\spring-aop-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-expression\5.0.0.RELEASE\spring-expression-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-messaging\5.0.0.RELEASE\spring-messaging-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-tx\5.0.0.RELEASE\spring-tx-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\retry\spring-retry\1.2.0.RELEASE\spring-retry-1.2.0.RELEASE.jar;E:\java\repository\org\apache\kafka\kafka-clients\0.11.0.0\kafka-clients-0.11.0.0.jar;E:\java\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;E:\java\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;E:\java\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;E:\java\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\java\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\java\repository\junit\junit\4.12\junit-4.12.jar;E:\java\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;E:\java\repository\org\springframework\spring-test\5.0.0.RELEASE\spring-test-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-core\5.0.0.RELEASE\spring-core-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jcl\5.0.0.RELEASE\spring-jcl-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jdbc\5.0.0.RELEASE\spring-jdbc-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-beans\5.0.0.RELEASE\spring-beans-5.0.0.RELEASE.jar;E:\java\repository\org\mybatis\mybatis\3.4.5\mybatis-3.4.5.jar;E:\java\repository\org\mybatis\mybatis-spring\1.3.1\mybatis-spring-1.3.1.jar;E:\java\repository\mysql\mysql-connector-java\5.1.44\mysql-connector-java-5.1.44.jar;E:\java\repository\c3p0\c3p0\0.9.1.2\c3p0-0.9.1.2.jar;E:\java\repository\commons-io\commons-io\2.6\commons-io-2.6.jar;E:\java\repository\joda-time\joda-time\2.9.9\joda-time-2.9.9.jar;, java.specification.name=Java Platform API Specification, java.class.version=52.0, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, maven.repo.local=E:\java\repository, os.version=6.3, user.home=C:\Users\vincent, user.timezone=Asia/Shanghai, java.awt.printerjob=sun.awt.windows.WPrinterJob, file.encoding=GBK, java.specification.version=1.8, java.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\test-classes;F:\git\mavenProject\file2DB\file2DB-service\target\classes;F:\git\mavenProject\file2DB\file2DB-common\target\file2DB-common-1.0-SNAPSHOT.jar;E:\java\repository\org\springframework\kafka\spring-kafka\2.0.0.RELEASE\spring-kafka-2.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-context\5.0.0.RELEASE\spring-context-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-aop\5.0.0.RELEASE\spring-aop-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-expression\5.0.0.RELEASE\spring-expression-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-messaging\5.0.0.RELEASE\spring-messaging-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-tx\5.0.0.RELEASE\spring-tx-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\retry\spring-retry\1.2.0.RELEASE\spring-retry-1.2.0.RELEASE.jar;E:\java\repository\org\apache\kafka\kafka-clients\0.11.0.0\kafka-clients-0.11.0.0.jar;E:\java\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;E:\java\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;E:\java\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;E:\java\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\java\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\java\repository\junit\junit\4.12\junit-4.12.jar;E:\java\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;E:\java\repository\org\springframework\spring-test\5.0.0.RELEASE\spring-test-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-core\5.0.0.RELEASE\spring-core-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jcl\5.0.0.RELEASE\spring-jcl-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jdbc\5.0.0.RELEASE\spring-jdbc-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-beans\5.0.0.RELEASE\spring-beans-5.0.0.RELEASE.jar;E:\java\repository\org\mybatis\mybatis\3.4.5\mybatis-3.4.5.jar;E:\java\repository\org\mybatis\mybatis-spring\1.3.1\mybatis-spring-1.3.1.jar;E:\java\repository\mysql\mysql-connector-java\5.1.44\mysql-connector-java-5.1.44.jar;E:\java\repository\c3p0\c3p0\0.9.1.2\c3p0-0.9.1.2.jar;E:\java\repository\commons-io\commons-io\2.6\commons-io-2.6.jar;E:\java\repository\joda-time\joda-time\2.9.9\joda-time-2.9.9.jar;, user.name=vincent, java.vm.specification.version=1.8, sun.java.command=F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefirebooter2477867052819822086.jar F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefire7735783549134567590tmp F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefire_08912352951682761711tmp, java.home=E:\Program Files\Java\jdk1.8.0_40\jre, sun.arch.data.model=64, user.language=zh, java.specification.vendor=Oracle Corporation, awt.toolkit=sun.awt.windows.WToolkit, java.vm.info=mixed mode, java.version=1.8.0_40, java.ext.dirs=E:\Program Files\Java\jdk1.8.0_40\jre\lib\ext;C:\WINDOWS\Sun\Java\lib\ext, sun.boot.class.path=E:\Program Files\Java\jdk1.8.0_40\jre\lib\resources.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\rt.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\sunrsasign.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jsse.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jce.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\charsets.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jfr.jar;E:\Program Files\Java\jdk1.8.0_40\jre\classes, java.vendor=Oracle Corporation, localRepository=E:\java\repository, file.separator=\, java.vendor.url.bug=http://bugreport.sun.com/bugreport/, sun.io.unicode.encoding=UnicodeLittle, sun.cpu.endian=little, sun.desktop=windows, sun.cpu.isalist=amd64}}, SystemEnvironmentPropertySource@124323713 {name='systemEnvironment', properties={PATH=E:\Program Files\Java\jdk1.8.0_40\bin;C:\Program Files (x86)\Common Files\NetSarang;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;E:\java\apache-maven-3.3.3\bin;E:\java\mysql-5.7.13-winx64\bin;E:\Program Files\MATLAB\R2012a\runtime\win64;E:\Program Files\MATLAB\R2012a\bin;E:\Users\vincent\AppData\Local\Android\sdk\platform-tools;F:\git\node-v6.11.4-win-x64;E:\Program Files\Git\bin;C:\Users\vincent\AppData\Local\Microsoft\WindowsApps;, USERDOMAIN_ROAMINGPROFILE=DESKTOP-8IAUFDG, GIT_HOME=E:\Program Files\Git, LOCALAPPDATA=C:\Users\vincent\AppData\Local, PROCESSOR_LEVEL=6, SYSTEMDRIVE=C:, COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files, USERDOMAIN=DESKTOP-8IAUFDG, FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer, LOGONSERVER=\\DESKTOP-8IAUFDG, JAVA_HOME=E:\Program Files\Java\jdk1.8.0_40, PROMPT=$P$G, SESSIONNAME=Console, ALLUSERSPROFILE=C:\ProgramData, PROGRAMFILES(X86)=C:\Program Files (x86), PROCESSOR_ARCHITECTURE=AMD64, MAVEN_HOME=E:\java\apache-maven-3.3.3, PROGRAMFILES=C:\Program Files, APPDATA=C:\Users\vincent\AppData\Roaming, PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files\Intel\, PROGRAMW6432=C:\Program Files, PROGRAMDATA=C:\ProgramData, SYSTEMROOT=C:\WINDOWS, USERNAME=vincent, FPS_BROWSER_USER_PROFILE_STRING=Default, ONEDRIVE=C:\Users\vincent\OneDrive, PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC, OS=Windows_NT, COMMONPROGRAMW6432=C:\Program Files\Common Files, COMPUTERNAME=DESKTOP-8IAUFDG, COMMONPROGRAMFILES=C:\Program Files\Common Files, COMSPEC=C:\WINDOWS\system32\cmd.exe, JAVA_HOME_X86=C:\ProgramData\Oracle\Java\javapath, PROCESSOR_REVISION=3c03, CLASSPATH=.;F:\git\jade\JADE-bin-4.5.0\jade\lib\jade.jar;, WINDIR=C:\WINDOWS, =F:=F:\git\mavenProject\file2DB\file2DB-service, HOMEPATH=\Users\vincent, TEMP=C:\Users\vincent\AppData\Local\Temp, HOMEDRIVE=C:, PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 60 Stepping 3, GenuineIntel, USERPROFILE=C:\Users\vincent, TMP=C:\Users\vincent\AppData\Local\Temp, PUBLIC=C:\Users\Public, NUMBER_OF_PROCESSORS=4}}]
2017-11-24 16:23:37.547 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved classpath location [org/dao/] to resources [URL [file:/F:/git/mavenProject/file2DB/file2DB-service/target/classes/org/dao/]]
2017-11-24 16:23:37.548 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\dao]
2017-11-24 16:23:37.548 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\dao] for files matching pattern [F:/git/mavenProject/file2DB/file2DB-service/target/classes/org/dao/**/*.class]
2017-11-24 16:23:37.548 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath*:org/dao/**/*.class] to resources [file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\dao\ExtractDao.class]]
2017-11-24 16:23:37.548 [main] DEBUG org.mybatis.spring.mapper.ClassPathMapperScanner - Identified candidate component class: file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\dao\ExtractDao.class]
2017-11-24 16:23:37.549 [main] DEBUG org.mybatis.spring.mapper.ClassPathMapperScanner - Creating MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface
2017-11-24 16:23:37.549 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#1'
2017-11-24 16:23:37.549 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#1'
2017-11-24 16:23:37.549 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#1' to allow for resolving potential circular references
2017-11-24 16:23:37.549 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking afterPropertiesSet() on bean with name 'org.mybatis.spring.mapper.MapperScannerConfigurer#1'
2017-11-24 16:23:37.549 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#1'
2017-11-24 16:23:37.549 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemProperties' with lowest search precedence
2017-11-24 16:23:37.549 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemEnvironment' with lowest search precedence
2017-11-24 16:23:37.549 [main] DEBUG org.springframework.core.env.StandardEnvironment - Initialized StandardEnvironment with PropertySources [MapPropertySource@980138431 {name='systemProperties', properties={idea.version=2017.2.6, java.runtime.name=Java(TM) SE Runtime Environment, sun.boot.library.path=E:\Program Files\Java\jdk1.8.0_40\jre\bin, java.vm.version=25.40-b25, java.vm.vendor=Oracle Corporation, java.vendor.url=http://java.oracle.com/, path.separator=;, java.vm.name=Java HotSpot(TM) 64-Bit Server VM, file.encoding.pkg=sun.io, user.country=CN, user.script=, sun.java.launcher=SUN_STANDARD, sun.os.patch.level=, java.vm.specification.name=Java Virtual Machine Specification, user.dir=F:\git\mavenProject\file2DB\file2DB-service, java.runtime.version=1.8.0_40-b25, basedir=F:\git\mavenProject\file2DB\file2DB-service, java.awt.graphicsenv=sun.awt.Win32GraphicsEnvironment, java.endorsed.dirs=E:\Program Files\Java\jdk1.8.0_40\jre\lib\endorsed, os.arch=amd64, surefire.real.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefirebooter2477867052819822086.jar, java.io.tmpdir=C:\Users\vincent\AppData\Local\Temp\, line.separator=
, java.vm.specification.vendor=Oracle Corporation, user.variant=, os.name=Windows 8.1, sun.jnu.encoding=GBK, java.library.path=E:\Program Files\Java\jdk1.8.0_40\jre\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;E:\Program Files\Java\jdk1.8.0_40\bin;C:\Program Files (x86)\Common Files\NetSarang;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;E:\java\apache-maven-3.3.3\bin;E:\java\mysql-5.7.13-winx64\bin;E:\Program Files\MATLAB\R2012a\runtime\win64;E:\Program Files\MATLAB\R2012a\bin;E:\Users\vincent\AppData\Local\Android\sdk\platform-tools;F:\git\node-v6.11.4-win-x64;E:\Program Files\Git\bin;C:\Users\vincent\AppData\Local\Microsoft\WindowsApps;;., surefire.test.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\test-classes;F:\git\mavenProject\file2DB\file2DB-service\target\classes;F:\git\mavenProject\file2DB\file2DB-common\target\file2DB-common-1.0-SNAPSHOT.jar;E:\java\repository\org\springframework\kafka\spring-kafka\2.0.0.RELEASE\spring-kafka-2.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-context\5.0.0.RELEASE\spring-context-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-aop\5.0.0.RELEASE\spring-aop-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-expression\5.0.0.RELEASE\spring-expression-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-messaging\5.0.0.RELEASE\spring-messaging-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-tx\5.0.0.RELEASE\spring-tx-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\retry\spring-retry\1.2.0.RELEASE\spring-retry-1.2.0.RELEASE.jar;E:\java\repository\org\apache\kafka\kafka-clients\0.11.0.0\kafka-clients-0.11.0.0.jar;E:\java\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;E:\java\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;E:\java\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;E:\java\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\java\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\java\repository\junit\junit\4.12\junit-4.12.jar;E:\java\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;E:\java\repository\org\springframework\spring-test\5.0.0.RELEASE\spring-test-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-core\5.0.0.RELEASE\spring-core-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jcl\5.0.0.RELEASE\spring-jcl-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jdbc\5.0.0.RELEASE\spring-jdbc-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-beans\5.0.0.RELEASE\spring-beans-5.0.0.RELEASE.jar;E:\java\repository\org\mybatis\mybatis\3.4.5\mybatis-3.4.5.jar;E:\java\repository\org\mybatis\mybatis-spring\1.3.1\mybatis-spring-1.3.1.jar;E:\java\repository\mysql\mysql-connector-java\5.1.44\mysql-connector-java-5.1.44.jar;E:\java\repository\c3p0\c3p0\0.9.1.2\c3p0-0.9.1.2.jar;E:\java\repository\commons-io\commons-io\2.6\commons-io-2.6.jar;E:\java\repository\joda-time\joda-time\2.9.9\joda-time-2.9.9.jar;, java.specification.name=Java Platform API Specification, java.class.version=52.0, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, maven.repo.local=E:\java\repository, os.version=6.3, user.home=C:\Users\vincent, user.timezone=Asia/Shanghai, java.awt.printerjob=sun.awt.windows.WPrinterJob, file.encoding=GBK, java.specification.version=1.8, java.class.path=F:\git\mavenProject\file2DB\file2DB-service\target\test-classes;F:\git\mavenProject\file2DB\file2DB-service\target\classes;F:\git\mavenProject\file2DB\file2DB-common\target\file2DB-common-1.0-SNAPSHOT.jar;E:\java\repository\org\springframework\kafka\spring-kafka\2.0.0.RELEASE\spring-kafka-2.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-context\5.0.0.RELEASE\spring-context-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-aop\5.0.0.RELEASE\spring-aop-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-expression\5.0.0.RELEASE\spring-expression-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-messaging\5.0.0.RELEASE\spring-messaging-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-tx\5.0.0.RELEASE\spring-tx-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\retry\spring-retry\1.2.0.RELEASE\spring-retry-1.2.0.RELEASE.jar;E:\java\repository\org\apache\kafka\kafka-clients\0.11.0.0\kafka-clients-0.11.0.0.jar;E:\java\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;E:\java\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;E:\java\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;E:\java\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\java\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\java\repository\junit\junit\4.12\junit-4.12.jar;E:\java\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;E:\java\repository\org\springframework\spring-test\5.0.0.RELEASE\spring-test-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-core\5.0.0.RELEASE\spring-core-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jcl\5.0.0.RELEASE\spring-jcl-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-jdbc\5.0.0.RELEASE\spring-jdbc-5.0.0.RELEASE.jar;E:\java\repository\org\springframework\spring-beans\5.0.0.RELEASE\spring-beans-5.0.0.RELEASE.jar;E:\java\repository\org\mybatis\mybatis\3.4.5\mybatis-3.4.5.jar;E:\java\repository\org\mybatis\mybatis-spring\1.3.1\mybatis-spring-1.3.1.jar;E:\java\repository\mysql\mysql-connector-java\5.1.44\mysql-connector-java-5.1.44.jar;E:\java\repository\c3p0\c3p0\0.9.1.2\c3p0-0.9.1.2.jar;E:\java\repository\commons-io\commons-io\2.6\commons-io-2.6.jar;E:\java\repository\joda-time\joda-time\2.9.9\joda-time-2.9.9.jar;, user.name=vincent, java.vm.specification.version=1.8, sun.java.command=F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefirebooter2477867052819822086.jar F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefire7735783549134567590tmp F:\git\mavenProject\file2DB\file2DB-service\target\surefire\surefire_08912352951682761711tmp, java.home=E:\Program Files\Java\jdk1.8.0_40\jre, sun.arch.data.model=64, user.language=zh, java.specification.vendor=Oracle Corporation, awt.toolkit=sun.awt.windows.WToolkit, java.vm.info=mixed mode, java.version=1.8.0_40, java.ext.dirs=E:\Program Files\Java\jdk1.8.0_40\jre\lib\ext;C:\WINDOWS\Sun\Java\lib\ext, sun.boot.class.path=E:\Program Files\Java\jdk1.8.0_40\jre\lib\resources.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\rt.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\sunrsasign.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jsse.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jce.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\charsets.jar;E:\Program Files\Java\jdk1.8.0_40\jre\lib\jfr.jar;E:\Program Files\Java\jdk1.8.0_40\jre\classes, java.vendor=Oracle Corporation, localRepository=E:\java\repository, file.separator=\, java.vendor.url.bug=http://bugreport.sun.com/bugreport/, sun.io.unicode.encoding=UnicodeLittle, sun.cpu.endian=little, sun.desktop=windows, sun.cpu.isalist=amd64}}, SystemEnvironmentPropertySource@888655833 {name='systemEnvironment', properties={PATH=E:\Program Files\Java\jdk1.8.0_40\bin;C:\Program Files (x86)\Common Files\NetSarang;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;E:\java\apache-maven-3.3.3\bin;E:\java\mysql-5.7.13-winx64\bin;E:\Program Files\MATLAB\R2012a\runtime\win64;E:\Program Files\MATLAB\R2012a\bin;E:\Users\vincent\AppData\Local\Android\sdk\platform-tools;F:\git\node-v6.11.4-win-x64;E:\Program Files\Git\bin;C:\Users\vincent\AppData\Local\Microsoft\WindowsApps;, USERDOMAIN_ROAMINGPROFILE=DESKTOP-8IAUFDG, GIT_HOME=E:\Program Files\Git, LOCALAPPDATA=C:\Users\vincent\AppData\Local, PROCESSOR_LEVEL=6, SYSTEMDRIVE=C:, COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files, USERDOMAIN=DESKTOP-8IAUFDG, FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer, LOGONSERVER=\\DESKTOP-8IAUFDG, JAVA_HOME=E:\Program Files\Java\jdk1.8.0_40, PROMPT=$P$G, SESSIONNAME=Console, ALLUSERSPROFILE=C:\ProgramData, PROGRAMFILES(X86)=C:\Program Files (x86), PROCESSOR_ARCHITECTURE=AMD64, MAVEN_HOME=E:\java\apache-maven-3.3.3, PROGRAMFILES=C:\Program Files, APPDATA=C:\Users\vincent\AppData\Roaming, PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files\Intel\, PROGRAMW6432=C:\Program Files, PROGRAMDATA=C:\ProgramData, SYSTEMROOT=C:\WINDOWS, USERNAME=vincent, FPS_BROWSER_USER_PROFILE_STRING=Default, ONEDRIVE=C:\Users\vincent\OneDrive, PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC, OS=Windows_NT, COMMONPROGRAMW6432=C:\Program Files\Common Files, COMPUTERNAME=DESKTOP-8IAUFDG, COMMONPROGRAMFILES=C:\Program Files\Common Files, COMSPEC=C:\WINDOWS\system32\cmd.exe, JAVA_HOME_X86=C:\ProgramData\Oracle\Java\javapath, PROCESSOR_REVISION=3c03, CLASSPATH=.;F:\git\jade\JADE-bin-4.5.0\jade\lib\jade.jar;, WINDIR=C:\WINDOWS, =F:=F:\git\mavenProject\file2DB\file2DB-service, HOMEPATH=\Users\vincent, TEMP=C:\Users\vincent\AppData\Local\Temp, HOMEDRIVE=C:, PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 60 Stepping 3, GenuineIntel, USERPROFILE=C:\Users\vincent, TMP=C:\Users\vincent\AppData\Local\Temp, PUBLIC=C:\Users\Public, NUMBER_OF_PROCESSORS=4}}]
2017-11-24 16:23:37.551 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved classpath location [org/dao/] to resources [URL [file:/F:/git/mavenProject/file2DB/file2DB-service/target/classes/org/dao/]]
2017-11-24 16:23:37.552 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\dao]
2017-11-24 16:23:37.552 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\dao] for files matching pattern [F:/git/mavenProject/file2DB/file2DB-service/target/classes/org/dao/**/*.class]
2017-11-24 16:23:37.552 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath*:org/dao/**/*.class] to resources [file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\dao\ExtractDao.class]]
2017-11-24 16:23:37.552 [main] DEBUG org.mybatis.spring.mapper.ClassPathMapperScanner - Identified candidate component class: file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\org\dao\ExtractDao.class]
2017-11-24 16:23:37.553 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-24 16:23:37.553 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-24 16:23:37.554 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'propertyConfigurer'
2017-11-24 16:23:37.554 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'propertyConfigurer'
2017-11-24 16:23:37.555 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'propertyConfigurer' to allow for resolving potential circular references
2017-11-24 16:23:37.563 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'propertyConfigurer'
2017-11-24 16:23:37.563 [main] DEBUG org.springframework.beans.factory.config.PropertyPlaceholderConfigurer - Loading properties file from class path resource [jdbc.properties]
2017-11-24 16:23:37.563 [main] DEBUG org.springframework.beans.factory.config.PropertyPlaceholderConfigurer - Loading properties file from class path resource [kafka.properties]
2017-11-24 16:23:37.570 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
2017-11-24 16:23:37.570 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
2017-11-24 16:23:37.570 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor' to allow for resolving potential circular references
2017-11-24 16:23:37.575 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
2017-11-24 16:23:37.575 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalRequiredAnnotationProcessor'
2017-11-24 16:23:37.575 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'org.springframework.context.annotation.internalRequiredAnnotationProcessor'
2017-11-24 16:23:37.576 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'org.springframework.context.annotation.internalRequiredAnnotationProcessor' to allow for resolving potential circular references
2017-11-24 16:23:37.578 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'org.springframework.context.annotation.internalRequiredAnnotationProcessor'
2017-11-24 16:23:37.579 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
2017-11-24 16:23:37.579 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
2017-11-24 16:23:37.582 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor' to allow for resolving potential circular references
2017-11-24 16:23:37.586 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
2017-11-24 16:23:37.588 [main] DEBUG org.springframework.context.support.GenericApplicationContext - Unable to locate MessageSource with name 'messageSource': using default [org.springframework.context.support.DelegatingMessageSource@10163d6]
2017-11-24 16:23:37.589 [main] DEBUG org.springframework.context.support.GenericApplicationContext - Unable to locate ApplicationEventMulticaster with name 'applicationEventMulticaster': using default [org.springframework.context.event.SimpleApplicationEventMulticaster@50ad3bc1]
2017-11-24 16:23:37.591 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@694abbdc: defining beans [extractServiceImpl,org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,propertyConfigurer,transactionManager,dataSource,sqlSessionFactory,org.mybatis.spring.mapper.MapperScannerConfigurer#0,consumer1,consumerFactory1,consumerFactory2,consumerFactory3,consumerFactory4,consumerFactory5,consumerFactory6,consumerFactory7,consumerFactory8,consumerFactory9,consumerFactory10,consumerFactory11,consumerFactory12,consumerFactory13,consumerFactory14,consumerFactory15,consumerFactory16,consumerFactory17,consumerFactory18,consumerFactory19,consumerFactory20,messageListernerConsumerService,messageListernerConsumerService2,messageListernerConsumerService3,messageListernerConsumerService4,messageListernerConsumerService5,messageListernerConsumerService6,messageListernerConsumerService7,messageListernerConsumerService8,messageListernerConsumerService9,messageListernerConsumerService10,messageListernerConsumerService11,messageListernerConsumerService12,messageListernerConsumerService13,messageListernerConsumerService14,messageListernerConsumerService15,messageListernerConsumerService16,messageListernerConsumerService17,messageListernerConsumerService18,messageListernerConsumerService19,messageListernerConsumerService20,containerProperties1,containerProperties2,containerProperties3,containerProperties4,containerProperties5,containerProperties6,containerProperties7,containerProperties8,containerProperties9,containerProperties10,containerProperties11,containerProperties12,containerProperties13,containerProperties14,containerProperties15,containerProperties16,containerProperties17,containerProperties18,containerProperties19,containerProperties20,messageListenerContainer,messageListenerContainer2,messageListenerContainer3,messageListenerContainer4,messageListenerContainer5,messageListenerContainer6,messageListenerContainer7,messageListenerContainer8,messageListenerContainer9,messageListenerContainer10,messageListenerContainer11,messageListenerContainer12,messageListenerContainer13,messageListenerContainer14,messageListenerContainer15,messageListenerContainer16,messageListenerContainer17,messageListenerContainer18,messageListenerContainer19,messageListenerContainer20,producerProperties,producerFactory,KafkaTemplate,org.mybatis.spring.mapper.MapperScannerConfigurer#1,extractDao]; root of factory hierarchy
2017-11-24 16:23:37.591 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:37.591 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'extractServiceImpl'
2017-11-24 16:23:37.598 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.service.impl.ExtractServiceImpl]: AutowiredFieldElement for org.dao.ExtractDao org.service.impl.ExtractServiceImpl.extractDao
2017-11-24 16:23:37.598 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'extractServiceImpl' to allow for resolving potential circular references
2017-11-24 16:23:37.602 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'extractServiceImpl': AutowiredFieldElement for org.dao.ExtractDao org.service.impl.ExtractServiceImpl.extractDao
2017-11-24 16:23:37.604 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:37.614 [main] DEBUG org.apache.ibatis.logging.LogFactory - Logging initialized using 'class org.apache.ibatis.logging.slf4j.Slf4jImpl' adapter.
2017-11-24 16:23:37.621 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'extractDao'
2017-11-24 16:23:37.622 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'extractDao'
2017-11-24 16:23:37.622 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'extractDao' to allow for resolving potential circular references
2017-11-24 16:23:37.629 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'sqlSessionFactory'
2017-11-24 16:23:37.629 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'sqlSessionFactory'
2017-11-24 16:23:37.630 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'sqlSessionFactory' to allow for resolving potential circular references
2017-11-24 16:23:37.636 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'dataSource'
2017-11-24 16:23:37.636 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'dataSource'
2017-11-24 16:23:37.913 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'dataSource' to allow for resolving potential circular references
2017-11-24 16:23:37.942 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'dataSource'
2017-11-24 16:23:37.943 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [F:\git\mavenProject\file2DB\file2DB-service\target\classes\mapper]
2017-11-24 16:23:37.943 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [F:\git\mavenProject\file2DB\file2DB-service\target\classes\mapper] for files matching pattern [F:/git/mavenProject/file2DB/file2DB-service/target/classes/mapper/*.xml]
2017-11-24 16:23:37.943 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath:mapper/*.xml] to resources [file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\mapper\Extract.xml]]
2017-11-24 16:23:37.944 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking afterPropertiesSet() on bean with name 'sqlSessionFactory'
2017-11-24 16:23:38.016 [main] DEBUG org.apache.ibatis.logging.LogFactory - Logging initialized using 'class org.apache.ibatis.logging.slf4j.Slf4jImpl' adapter.
2017-11-24 16:23:38.017 [main] DEBUG org.mybatis.spring.SqlSessionFactoryBean - Parsed configuration file: 'class path resource [mybatis/mybatis-config.xml]'
2017-11-24 16:23:38.044 [main] DEBUG org.mybatis.spring.SqlSessionFactoryBean - Parsed mapper file: 'file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\mapper\Extract.xml]'
2017-11-24 16:23:38.046 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'sqlSessionFactory'
2017-11-24 16:23:38.051 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking afterPropertiesSet() on bean with name 'extractDao'
2017-11-24 16:23:38.051 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'extractDao'
2017-11-24 16:23:38.053 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'extractServiceImpl' to bean named 'extractDao'
2017-11-24 16:23:38.054 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'extractServiceImpl'
2017-11-24 16:23:38.054 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
2017-11-24 16:23:38.054 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
2017-11-24 16:23:38.054 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'org.springframework.context.annotation.internalRequiredAnnotationProcessor'
2017-11-24 16:23:38.054 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
2017-11-24 16:23:38.054 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerProcessor'
2017-11-24 16:23:38.054 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'org.springframework.context.event.internalEventListenerProcessor'
2017-11-24 16:23:38.055 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'org.springframework.context.event.internalEventListenerProcessor' to allow for resolving potential circular references
2017-11-24 16:23:38.057 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'org.springframework.context.event.internalEventListenerProcessor'
2017-11-24 16:23:38.057 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory'
2017-11-24 16:23:38.057 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'org.springframework.context.event.internalEventListenerFactory'
2017-11-24 16:23:38.057 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'org.springframework.context.event.internalEventListenerFactory' to allow for resolving potential circular references
2017-11-24 16:23:38.059 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'org.springframework.context.event.internalEventListenerFactory'
2017-11-24 16:23:38.059 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'propertyConfigurer'
2017-11-24 16:23:38.059 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'transactionManager'
2017-11-24 16:23:38.059 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'transactionManager'
2017-11-24 16:23:38.065 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'transactionManager' to allow for resolving potential circular references
2017-11-24 16:23:38.068 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.068 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking afterPropertiesSet() on bean with name 'transactionManager'
2017-11-24 16:23:38.068 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'transactionManager'
2017-11-24 16:23:38.068 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.068 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'sqlSessionFactory'
2017-11-24 16:23:38.068 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#0'
2017-11-24 16:23:38.068 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumer1'
2017-11-24 16:23:38.069 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumer1'
2017-11-24 16:23:38.073 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumer1' to allow for resolving potential circular references
2017-11-24 16:23:38.112 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumer1'
2017-11-24 16:23:38.112 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory1'
2017-11-24 16:23:38.112 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory1'
2017-11-24 16:23:38.114 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.116 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory1' to allow for resolving potential circular references
2017-11-24 16:23:38.118 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory1'
2017-11-24 16:23:38.118 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory2'
2017-11-24 16:23:38.118 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory2'
2017-11-24 16:23:38.118 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory2' to allow for resolving potential circular references
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory2'
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory3'
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory3'
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory3' to allow for resolving potential circular references
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory3'
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory4'
2017-11-24 16:23:38.119 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory4'
2017-11-24 16:23:38.120 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.120 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory4' to allow for resolving potential circular references
2017-11-24 16:23:38.120 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory4'
2017-11-24 16:23:38.120 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory5'
2017-11-24 16:23:38.120 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory5'
2017-11-24 16:23:38.120 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.120 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory5' to allow for resolving potential circular references
2017-11-24 16:23:38.120 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory5'
2017-11-24 16:23:38.121 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory6'
2017-11-24 16:23:38.121 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory6'
2017-11-24 16:23:38.121 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.121 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory6' to allow for resolving potential circular references
2017-11-24 16:23:38.121 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory6'
2017-11-24 16:23:38.121 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory7'
2017-11-24 16:23:38.121 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory7'
2017-11-24 16:23:38.121 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory7' to allow for resolving potential circular references
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory7'
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory8'
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory8'
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory8' to allow for resolving potential circular references
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory8'
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory9'
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory9'
2017-11-24 16:23:38.122 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.123 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory9' to allow for resolving potential circular references
2017-11-24 16:23:38.124 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory9'
2017-11-24 16:23:38.124 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory10'
2017-11-24 16:23:38.124 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory10'
2017-11-24 16:23:38.124 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.124 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory10' to allow for resolving potential circular references
2017-11-24 16:23:38.124 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory10'
2017-11-24 16:23:38.124 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory11'
2017-11-24 16:23:38.124 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory11'
2017-11-24 16:23:38.125 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.125 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory11' to allow for resolving potential circular references
2017-11-24 16:23:38.125 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory11'
2017-11-24 16:23:38.125 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory12'
2017-11-24 16:23:38.125 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory12'
2017-11-24 16:23:38.125 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.125 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory12' to allow for resolving potential circular references
2017-11-24 16:23:38.125 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory12'
2017-11-24 16:23:38.127 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory13'
2017-11-24 16:23:38.127 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory13'
2017-11-24 16:23:38.127 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.128 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory13' to allow for resolving potential circular references
2017-11-24 16:23:38.128 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory13'
2017-11-24 16:23:38.128 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory14'
2017-11-24 16:23:38.128 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory14'
2017-11-24 16:23:38.128 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory14' to allow for resolving potential circular references
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory14'
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory15'
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory15'
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory15' to allow for resolving potential circular references
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory15'
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory16'
2017-11-24 16:23:38.129 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory16'
2017-11-24 16:23:38.130 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.130 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory16' to allow for resolving potential circular references
2017-11-24 16:23:38.130 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory16'
2017-11-24 16:23:38.130 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory17'
2017-11-24 16:23:38.130 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory17'
2017-11-24 16:23:38.130 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory17' to allow for resolving potential circular references
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory17'
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory18'
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory18'
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory18' to allow for resolving potential circular references
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory18'
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory19'
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory19'
2017-11-24 16:23:38.131 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory19' to allow for resolving potential circular references
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory19'
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'consumerFactory20'
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'consumerFactory20'
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumer1'
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'consumerFactory20' to allow for resolving potential circular references
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'consumerFactory20'
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService'
2017-11-24 16:23:38.132 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService'
2017-11-24 16:23:38.136 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener.extractService
2017-11-24 16:23:38.137 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener.dataSource
2017-11-24 16:23:38.137 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService' to allow for resolving potential circular references
2017-11-24 16:23:38.138 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener.extractService
2017-11-24 16:23:38.138 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.138 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.138 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.138 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener.dataSource
2017-11-24 16:23:38.138 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.139 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.139 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService' to bean named 'dataSource'
2017-11-24 16:23:38.139 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService'
2017-11-24 16:23:38.140 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService2'
2017-11-24 16:23:38.140 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService2'
2017-11-24 16:23:38.141 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener2]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener2.extractService
2017-11-24 16:23:38.141 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener2]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener2.dataSource
2017-11-24 16:23:38.141 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService2' to allow for resolving potential circular references
2017-11-24 16:23:38.142 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService2': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener2.extractService
2017-11-24 16:23:38.142 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.142 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.142 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService2' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.142 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService2': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener2.dataSource
2017-11-24 16:23:38.143 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.143 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.143 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService2' to bean named 'dataSource'
2017-11-24 16:23:38.143 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService2'
2017-11-24 16:23:38.143 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService3'
2017-11-24 16:23:38.143 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService3'
2017-11-24 16:23:38.144 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener3]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener3.extractService
2017-11-24 16:23:38.144 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener3]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener3.dataSource
2017-11-24 16:23:38.144 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService3' to allow for resolving potential circular references
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService3': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener3.extractService
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.147 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService3' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService3': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener3.dataSource
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.147 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService3' to bean named 'dataSource'
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService3'
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService4'
2017-11-24 16:23:38.147 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService4'
2017-11-24 16:23:38.149 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener4]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener4.extractService
2017-11-24 16:23:38.149 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener4]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener4.dataSource
2017-11-24 16:23:38.149 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService4' to allow for resolving potential circular references
2017-11-24 16:23:38.151 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService4': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener4.extractService
2017-11-24 16:23:38.151 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.151 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.151 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService4' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.151 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService4': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener4.dataSource
2017-11-24 16:23:38.152 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.152 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.152 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService4' to bean named 'dataSource'
2017-11-24 16:23:38.152 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService4'
2017-11-24 16:23:38.152 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService5'
2017-11-24 16:23:38.152 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService5'
2017-11-24 16:23:38.153 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener5]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener5.extractService
2017-11-24 16:23:38.153 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener5]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener5.dataSource
2017-11-24 16:23:38.153 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService5' to allow for resolving potential circular references
2017-11-24 16:23:38.154 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService5': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener5.extractService
2017-11-24 16:23:38.154 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.155 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.155 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService5' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.155 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService5': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener5.dataSource
2017-11-24 16:23:38.155 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.155 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.155 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService5' to bean named 'dataSource'
2017-11-24 16:23:38.155 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService5'
2017-11-24 16:23:38.155 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService6'
2017-11-24 16:23:38.155 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService6'
2017-11-24 16:23:38.158 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener6]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener6.extractService
2017-11-24 16:23:38.158 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener6]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener6.dataSource
2017-11-24 16:23:38.158 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService6' to allow for resolving potential circular references
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService6': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener6.extractService
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.160 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService6' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService6': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener6.dataSource
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.160 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService6' to bean named 'dataSource'
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService6'
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService7'
2017-11-24 16:23:38.160 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService7'
2017-11-24 16:23:38.161 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener7]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener7.extractService
2017-11-24 16:23:38.162 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener7]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener7.dataSource
2017-11-24 16:23:38.162 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService7' to allow for resolving potential circular references
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService7': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener7.extractService
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.163 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService7' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService7': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener7.dataSource
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.163 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService7' to bean named 'dataSource'
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService7'
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService8'
2017-11-24 16:23:38.163 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService8'
2017-11-24 16:23:38.165 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener8]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener8.extractService
2017-11-24 16:23:38.165 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener8]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener8.dataSource
2017-11-24 16:23:38.165 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService8' to allow for resolving potential circular references
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService8': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener8.extractService
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.166 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService8' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService8': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener8.dataSource
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.166 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService8' to bean named 'dataSource'
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService8'
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService9'
2017-11-24 16:23:38.166 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService9'
2017-11-24 16:23:38.167 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener9]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener9.extractService
2017-11-24 16:23:38.167 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener9]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener9.dataSource
2017-11-24 16:23:38.167 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService9' to allow for resolving potential circular references
2017-11-24 16:23:38.168 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService9': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener9.extractService
2017-11-24 16:23:38.168 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.168 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.169 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService9' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.169 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService9': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener9.dataSource
2017-11-24 16:23:38.169 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.169 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.169 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService9' to bean named 'dataSource'
2017-11-24 16:23:38.169 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService9'
2017-11-24 16:23:38.169 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService10'
2017-11-24 16:23:38.169 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService10'
2017-11-24 16:23:38.171 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener10]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener10.extractService
2017-11-24 16:23:38.171 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener10]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener10.dataSource
2017-11-24 16:23:38.171 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService10' to allow for resolving potential circular references
2017-11-24 16:23:38.172 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService10': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener10.extractService
2017-11-24 16:23:38.172 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.173 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.173 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService10' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.173 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService10': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener10.dataSource
2017-11-24 16:23:38.173 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.173 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.173 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService10' to bean named 'dataSource'
2017-11-24 16:23:38.173 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService10'
2017-11-24 16:23:38.173 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService11'
2017-11-24 16:23:38.173 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService11'
2017-11-24 16:23:38.174 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener11]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener11.extractService
2017-11-24 16:23:38.174 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener11]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener11.dataSource
2017-11-24 16:23:38.174 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService11' to allow for resolving potential circular references
2017-11-24 16:23:38.175 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService11': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener11.extractService
2017-11-24 16:23:38.176 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.176 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.176 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService11' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.176 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService11': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener11.dataSource
2017-11-24 16:23:38.176 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.176 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.176 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService11' to bean named 'dataSource'
2017-11-24 16:23:38.176 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService11'
2017-11-24 16:23:38.176 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService12'
2017-11-24 16:23:38.176 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService12'
2017-11-24 16:23:38.177 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener12]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener12.extractService
2017-11-24 16:23:38.177 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener12]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener12.dataSource
2017-11-24 16:23:38.177 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService12' to allow for resolving potential circular references
2017-11-24 16:23:38.178 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService12': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener12.extractService
2017-11-24 16:23:38.178 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.178 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.178 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService12' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.179 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService12': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener12.dataSource
2017-11-24 16:23:38.179 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.179 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.179 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService12' to bean named 'dataSource'
2017-11-24 16:23:38.179 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService12'
2017-11-24 16:23:38.179 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService13'
2017-11-24 16:23:38.179 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService13'
2017-11-24 16:23:38.180 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener13]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener13.extractService
2017-11-24 16:23:38.180 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener13]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener13.dataSource
2017-11-24 16:23:38.180 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService13' to allow for resolving potential circular references
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService13': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener13.extractService
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.181 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService13' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService13': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener13.dataSource
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.181 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService13' to bean named 'dataSource'
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService13'
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService14'
2017-11-24 16:23:38.181 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService14'
2017-11-24 16:23:38.182 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener14]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener14.extractService
2017-11-24 16:23:38.182 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener14]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener14.dataSource
2017-11-24 16:23:38.182 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService14' to allow for resolving potential circular references
2017-11-24 16:23:38.183 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService14': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener14.extractService
2017-11-24 16:23:38.183 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.183 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.183 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService14' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.183 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService14': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener14.dataSource
2017-11-24 16:23:38.183 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.183 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.184 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService14' to bean named 'dataSource'
2017-11-24 16:23:38.184 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService14'
2017-11-24 16:23:38.184 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService15'
2017-11-24 16:23:38.184 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService15'
2017-11-24 16:23:38.185 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener15]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener15.extractService
2017-11-24 16:23:38.185 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener15]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener15.dataSource
2017-11-24 16:23:38.185 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService15' to allow for resolving potential circular references
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService15': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener15.extractService
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.187 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService15' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService15': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener15.dataSource
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.187 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService15' to bean named 'dataSource'
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService15'
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService16'
2017-11-24 16:23:38.187 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService16'
2017-11-24 16:23:38.188 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener16]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener16.extractService
2017-11-24 16:23:38.188 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener16]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener16.dataSource
2017-11-24 16:23:38.188 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService16' to allow for resolving potential circular references
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService16': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener16.extractService
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.190 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService16' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService16': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener16.dataSource
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.190 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService16' to bean named 'dataSource'
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService16'
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService17'
2017-11-24 16:23:38.190 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService17'
2017-11-24 16:23:38.191 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener17]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener17.extractService
2017-11-24 16:23:38.191 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener17]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener17.dataSource
2017-11-24 16:23:38.191 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService17' to allow for resolving potential circular references
2017-11-24 16:23:38.192 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService17': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener17.extractService
2017-11-24 16:23:38.192 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.192 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.193 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService17' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.193 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService17': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener17.dataSource
2017-11-24 16:23:38.193 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.193 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.193 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService17' to bean named 'dataSource'
2017-11-24 16:23:38.193 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService17'
2017-11-24 16:23:38.193 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService18'
2017-11-24 16:23:38.193 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService18'
2017-11-24 16:23:38.194 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener18]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener18.extractService
2017-11-24 16:23:38.194 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener18]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener18.dataSource
2017-11-24 16:23:38.194 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService18' to allow for resolving potential circular references
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService18': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener18.extractService
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.195 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService18' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService18': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener18.dataSource
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.195 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService18' to bean named 'dataSource'
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService18'
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService19'
2017-11-24 16:23:38.195 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService19'
2017-11-24 16:23:38.196 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener19]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener19.extractService
2017-11-24 16:23:38.196 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener19]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener19.dataSource
2017-11-24 16:23:38.196 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService19' to allow for resolving potential circular references
2017-11-24 16:23:38.197 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService19': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener19.extractService
2017-11-24 16:23:38.197 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.197 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.197 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService19' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.197 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService19': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener19.dataSource
2017-11-24 16:23:38.197 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.198 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.198 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService19' to bean named 'dataSource'
2017-11-24 16:23:38.198 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService19'
2017-11-24 16:23:38.198 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListernerConsumerService20'
2017-11-24 16:23:38.198 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListernerConsumerService20'
2017-11-24 16:23:38.199 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener20]: AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener20.extractService
2017-11-24 16:23:38.199 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Registered injected element on class [org.taian.KafkaConsumerListener20]: AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener20.dataSource
2017-11-24 16:23:38.199 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListernerConsumerService20' to allow for resolving potential circular references
2017-11-24 16:23:38.199 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService20': AutowiredFieldElement for org.service.ExtractService org.taian.KafkaConsumerListener20.extractService
2017-11-24 16:23:38.200 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.200 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.200 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService20' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.200 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'messageListernerConsumerService20': AutowiredFieldElement for com.mchange.v2.c3p0.ComboPooledDataSource org.taian.KafkaConsumerListener20.dataSource
2017-11-24 16:23:38.200 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.200 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'dataSource'
2017-11-24 16:23:38.200 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'messageListernerConsumerService20' to bean named 'dataSource'
2017-11-24 16:23:38.200 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListernerConsumerService20'
2017-11-24 16:23:38.200 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties1'
2017-11-24 16:23:38.200 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties1'
2017-11-24 16:23:38.203 [main] DEBUG org.springframework.beans.BeanUtils - No property editor [org.springframework.kafka.support.TopicPartitionInitialOffsetEditor] found for type org.springframework.kafka.support.TopicPartitionInitialOffset according to 'Editor' suffix convention
2017-11-24 16:23:38.204 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties1' to allow for resolving potential circular references
2017-11-24 16:23:38.205 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService'
2017-11-24 16:23:38.205 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties1'
2017-11-24 16:23:38.205 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties2'
2017-11-24 16:23:38.205 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties2'
2017-11-24 16:23:38.206 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties2' to allow for resolving potential circular references
2017-11-24 16:23:38.206 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService2'
2017-11-24 16:23:38.206 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties2'
2017-11-24 16:23:38.207 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties3'
2017-11-24 16:23:38.207 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties3'
2017-11-24 16:23:38.207 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties3' to allow for resolving potential circular references
2017-11-24 16:23:38.207 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService3'
2017-11-24 16:23:38.207 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties3'
2017-11-24 16:23:38.207 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties4'
2017-11-24 16:23:38.207 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties4'
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties4' to allow for resolving potential circular references
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService4'
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties4'
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties5'
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties5'
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties5' to allow for resolving potential circular references
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService5'
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties5'
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties6'
2017-11-24 16:23:38.208 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties6'
2017-11-24 16:23:38.209 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties6' to allow for resolving potential circular references
2017-11-24 16:23:38.209 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService6'
2017-11-24 16:23:38.209 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties6'
2017-11-24 16:23:38.209 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties7'
2017-11-24 16:23:38.209 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties7'
2017-11-24 16:23:38.209 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties7' to allow for resolving potential circular references
2017-11-24 16:23:38.209 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService7'
2017-11-24 16:23:38.209 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties7'
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties8'
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties8'
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties8' to allow for resolving potential circular references
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService8'
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties8'
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties9'
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties9'
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties9' to allow for resolving potential circular references
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService9'
2017-11-24 16:23:38.210 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties9'
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties10'
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties10'
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties10' to allow for resolving potential circular references
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService10'
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties10'
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties11'
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties11'
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties11' to allow for resolving potential circular references
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService11'
2017-11-24 16:23:38.211 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties11'
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties12'
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties12'
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties12' to allow for resolving potential circular references
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService12'
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties12'
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties13'
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties13'
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties13' to allow for resolving potential circular references
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService13'
2017-11-24 16:23:38.212 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties13'
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties14'
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties14'
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties14' to allow for resolving potential circular references
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService14'
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties14'
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties15'
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties15'
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties15' to allow for resolving potential circular references
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService15'
2017-11-24 16:23:38.213 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties15'
2017-11-24 16:23:38.214 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties16'
2017-11-24 16:23:38.214 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties16'
2017-11-24 16:23:38.214 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties16' to allow for resolving potential circular references
2017-11-24 16:23:38.214 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService16'
2017-11-24 16:23:38.214 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties16'
2017-11-24 16:23:38.214 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties17'
2017-11-24 16:23:38.214 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties17'
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties17' to allow for resolving potential circular references
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService17'
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties17'
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties18'
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties18'
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties18' to allow for resolving potential circular references
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService18'
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties18'
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties19'
2017-11-24 16:23:38.215 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties19'
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties19' to allow for resolving potential circular references
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService19'
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties19'
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'containerProperties20'
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'containerProperties20'
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'containerProperties20' to allow for resolving potential circular references
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListernerConsumerService20'
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'containerProperties20'
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer'
2017-11-24 16:23:38.216 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer'
2017-11-24 16:23:38.218 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory1'
2017-11-24 16:23:38.218 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties1'
2017-11-24 16:23:38.221 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer' to allow for resolving potential circular references
2017-11-24 16:23:38.227 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer'
2017-11-24 16:23:38.245 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.245 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.253 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.262 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.280 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.281 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.281 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.281 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.281 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.281 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.282 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.294 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.294 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.294 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.296 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.298 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.298 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.298 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.300 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.301 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.301 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.302 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.302 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.305 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer'
2017-11-24 16:23:38.305 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer2'
2017-11-24 16:23:38.305 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer2'
2017-11-24 16:23:38.306 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory2'
2017-11-24 16:23:38.306 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties2'
2017-11-24 16:23:38.306 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.306 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer2' to allow for resolving potential circular references
2017-11-24 16:23:38.306 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer2'
2017-11-24 16:23:38.307 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.307 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.307 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.307 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.309 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.309 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.309 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.309 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.309 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.309 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.309 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.310 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.310 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.310 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.310 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.310 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.310 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.310 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.311 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.311 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.311 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.311 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.311 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.311 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer2'
2017-11-24 16:23:38.311 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer3'
2017-11-24 16:23:38.311 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer3'
2017-11-24 16:23:38.311 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory3'
2017-11-24 16:23:38.311 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties3'
2017-11-24 16:23:38.312 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.312 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer3' to allow for resolving potential circular references
2017-11-24 16:23:38.312 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer3'
2017-11-24 16:23:38.312 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.312 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.313 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.313 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.313 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.314 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.314 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.315 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.315 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.315 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.315 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.315 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.316 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.316 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.316 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.316 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.316 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.316 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.317 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.318 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.318 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.318 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.319 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.319 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.319 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.319 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.319 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.317 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.325 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.325 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.327 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.328 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.328 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.328 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.328 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.328 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.328 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.328 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer3'
2017-11-24 16:23:38.329 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer4'
2017-11-24 16:23:38.329 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.329 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer4'
2017-11-24 16:23:38.329 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory4'
2017-11-24 16:23:38.329 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties4'
2017-11-24 16:23:38.329 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.329 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer4' to allow for resolving potential circular references
2017-11-24 16:23:38.329 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer4'
2017-11-24 16:23:38.330 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.330 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.330 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.330 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.330 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.330 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.330 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.330 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.331 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.331 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.331 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.332 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.333 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.333 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.333 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.333 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.333 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.333 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.333 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.333 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.333 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.333 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer4'
2017-11-24 16:23:38.334 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer5'
2017-11-24 16:23:38.334 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer5'
2017-11-24 16:23:38.333 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.334 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory5'
2017-11-24 16:23:38.334 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties5'
2017-11-24 16:23:38.334 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.334 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer5' to allow for resolving potential circular references
2017-11-24 16:23:38.334 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.334 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer5'
2017-11-24 16:23:38.335 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.335 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.335 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.335 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.335 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.335 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.335 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.336 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.336 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.338 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.338 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.338 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.338 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.338 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.338 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.338 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.339 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.339 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.339 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.340 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.340 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.340 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.344 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.344 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.344 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.344 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.344 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.344 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.344 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer5'
2017-11-24 16:23:38.344 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer6'
2017-11-24 16:23:38.344 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer6'
2017-11-24 16:23:38.347 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory6'
2017-11-24 16:23:38.347 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties6'
2017-11-24 16:23:38.347 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer6' to allow for resolving potential circular references
2017-11-24 16:23:38.347 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer6'
2017-11-24 16:23:38.348 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.348 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.348 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.348 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.349 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.349 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.349 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.351 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.351 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.351 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.351 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.351 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.351 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.351 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.351 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.351 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.352 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.352 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer6'
2017-11-24 16:23:38.352 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer7'
2017-11-24 16:23:38.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer7'
2017-11-24 16:23:38.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory7'
2017-11-24 16:23:38.352 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.352 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties7'
2017-11-24 16:23:38.353 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.353 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.353 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer7' to allow for resolving potential circular references
2017-11-24 16:23:38.353 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer7'
2017-11-24 16:23:38.353 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.354 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.354 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.354 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.354 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.354 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.355 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.355 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.355 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.355 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.355 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.355 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.355 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.355 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.355 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.355 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.355 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.356 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.357 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.357 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.357 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.357 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer7'
2017-11-24 16:23:38.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer8'
2017-11-24 16:23:38.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer8'
2017-11-24 16:23:38.357 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory8'
2017-11-24 16:23:38.357 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties8'
2017-11-24 16:23:38.358 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer8' to allow for resolving potential circular references
2017-11-24 16:23:38.358 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer8'
2017-11-24 16:23:38.358 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.358 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.358 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.359 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.359 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.359 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.359 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.359 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.359 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.360 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.360 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.361 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.361 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.361 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.361 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer8'
2017-11-24 16:23:38.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer9'
2017-11-24 16:23:38.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer9'
2017-11-24 16:23:38.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory9'
2017-11-24 16:23:38.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties9'
2017-11-24 16:23:38.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer9' to allow for resolving potential circular references
2017-11-24 16:23:38.362 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer9'
2017-11-24 16:23:38.364 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.364 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.364 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.364 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.364 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.365 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.366 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.366 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.366 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.366 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.366 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.367 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.367 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.367 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.367 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.367 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.367 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.367 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.367 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.368 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.368 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.368 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.369 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.369 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.369 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.369 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.369 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.369 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.369 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.369 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.369 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.369 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer9'
2017-11-24 16:23:38.369 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer10'
2017-11-24 16:23:38.369 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer10'
2017-11-24 16:23:38.370 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory10'
2017-11-24 16:23:38.370 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties10'
2017-11-24 16:23:38.370 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer10' to allow for resolving potential circular references
2017-11-24 16:23:38.370 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer10'
2017-11-24 16:23:38.371 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.371 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.371 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.371 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.372 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.372 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.372 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.372 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.372 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.372 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.372 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.372 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.375 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.375 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.376 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.377 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.377 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.377 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.377 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.377 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.377 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.377 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.377 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer10'
2017-11-24 16:23:38.377 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer11'
2017-11-24 16:23:38.377 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer11'
2017-11-24 16:23:38.377 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.377 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory11'
2017-11-24 16:23:38.377 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties11'
2017-11-24 16:23:38.378 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.378 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer11' to allow for resolving potential circular references
2017-11-24 16:23:38.378 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer11'
2017-11-24 16:23:38.378 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.378 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.378 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.379 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.379 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.379 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.379 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.379 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.379 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.379 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.381 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.382 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.382 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.382 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.382 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.382 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.382 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.382 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.383 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer11'
2017-11-24 16:23:38.383 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer12'
2017-11-24 16:23:38.383 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer12'
2017-11-24 16:23:38.383 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.383 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.383 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.383 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.384 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.383 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.384 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.384 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.384 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.384 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.383 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.385 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.383 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.383 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.386 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.383 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.386 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.386 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.389 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.389 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.390 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.391 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818391, latencyMs=33, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-7}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.391 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.391 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.391 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.392 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818392, latencyMs=84, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-1}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.392 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.392 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.389 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.393 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818393, latencyMs=29, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-8}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.393 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.393 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.394 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.394 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.394 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.394 [messageListenerContainer-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.394 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.389 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.395 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818395, latencyMs=41, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-6}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.395 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.395 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.396 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.396 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@7420a76d)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.396 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818390, latencyMs=56, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-4}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.396 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.396 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.396 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.396 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.396 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.396 [messageListenerContainer8-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.396 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.396 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@71f6b19d)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.396 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.396 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.396 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.396 [messageListenerContainer7-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.396 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.396 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.396 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@45e6d2d9)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.396 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.396 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.396 [messageListenerContainer6-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.396 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.397 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@487bc3fa)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.397 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.397 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.391 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.397 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.396 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818391, latencyMs=14, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-10}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.397 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.397 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.396 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.397 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.397 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.397 [messageListenerContainer4-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.397 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.397 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.397 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.397 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@38f8fe11)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.397 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.397 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.397 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.397 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.397 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.397 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.397 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.397 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.397 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.398 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.398 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.397 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.397 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818397, latencyMs=26, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-9}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.397 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.397 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.398 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.398 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.398 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.398 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.398 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.398 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.398 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.398 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.398 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.398 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.398 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.398 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.398 [messageListenerContainer10-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.398 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.398 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@7420ed41)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.398 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.398 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.399 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.399 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.399 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.399 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.398 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.399 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.399 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.399 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.399 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.399 [messageListenerContainer9-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.399 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.398 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.399 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@668f9b7f)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.399 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.399 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.400 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.400 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.400 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.383 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.400 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.400 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.400 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.400 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.400 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.400 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.400 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.401 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.401 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.385 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory12'
2017-11-24 16:23:38.402 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties12'
2017-11-24 16:23:38.402 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.403 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818403, latencyMs=54, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-5}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.403 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.403 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@4b63e135)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.404 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.405 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.405 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.405 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.406 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818406, latencyMs=93, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-2}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.406 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.406 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.409 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer12' to allow for resolving potential circular references
2017-11-24 16:23:38.409 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.409 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.409 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.409 [messageListenerContainer2-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.409 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer12'
2017-11-24 16:23:38.409 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.409 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@3aa841a7)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.409 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.409 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.409 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.410 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.410 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.410 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.410 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.410 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.410 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.410 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.410 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.411 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.411 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.411 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.411 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.411 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.412 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.412 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.412 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.412 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.412 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.413 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.413 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.413 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.413 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.413 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.413 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.413 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer12'
2017-11-24 16:23:38.413 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer13'
2017-11-24 16:23:38.413 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer13'
2017-11-24 16:23:38.413 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory13'
2017-11-24 16:23:38.413 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties13'
2017-11-24 16:23:38.413 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.414 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer13' to allow for resolving potential circular references
2017-11-24 16:23:38.414 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer13'
2017-11-24 16:23:38.414 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818414, latencyMs=85, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-3}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.414 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.414 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.414 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.414 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.414 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.414 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.414 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.414 [messageListenerContainer3-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.415 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.415 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@691a1545)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.415 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.415 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.415 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.415 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.415 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.415 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.415 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.416 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.416 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.417 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.417 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.417 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.417 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.417 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.417 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.417 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.418 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.418 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.418 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.419 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818420, latencyMs=10, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-11}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.420 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer13'
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.420 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer14'
2017-11-24 16:23:38.420 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer14'
2017-11-24 16:23:38.420 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory14'
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.420 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@2e22b2f7)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.421 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.421 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.421 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.421 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.421 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.421 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.421 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties14'
2017-11-24 16:23:38.422 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.422 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer14' to allow for resolving potential circular references
2017-11-24 16:23:38.423 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer14'
2017-11-24 16:23:38.423 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.423 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.423 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.423 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.425 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.425 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.425 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.425 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.425 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.425 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.426 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.426 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.426 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.426 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.426 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.428 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer14'
2017-11-24 16:23:38.428 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer15'
2017-11-24 16:23:38.428 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer15'
2017-11-24 16:23:38.428 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory15'
2017-11-24 16:23:38.429 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties15'
2017-11-24 16:23:38.430 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.430 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer15' to allow for resolving potential circular references
2017-11-24 16:23:38.430 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer15'
2017-11-24 16:23:38.430 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.430 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.431 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.430 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.431 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.431 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.431 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.431 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.431 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.432 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.432 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.432 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.433 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.433 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.433 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.433 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.433 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.433 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.433 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.433 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.433 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.433 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.433 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.433 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.433 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.434 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.434 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.434 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.434 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.434 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.435 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.434 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.435 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.435 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer15'
2017-11-24 16:23:38.435 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer16'
2017-11-24 16:23:38.435 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer16'
2017-11-24 16:23:38.436 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.436 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.436 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.436 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.436 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.436 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.436 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.438 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818438, latencyMs=6, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-12}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.438 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.438 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@176c6918)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.439 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.441 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.441 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.442 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.444 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.445 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818445, latencyMs=10, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-13}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.445 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.445 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@5aa13584)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.446 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.447 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory16'
2017-11-24 16:23:38.447 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.447 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties16'
2017-11-24 16:23:38.447 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.450 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.450 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.451 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.451 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.451 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.451 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.451 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.452 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.452 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.452 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.452 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.452 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.452 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.452 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.453 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.453 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.454 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.454 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.455 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.457 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818457, latencyMs=7, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-15}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.457 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.457 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@9f4db5b)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.458 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.460 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.465 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.466 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.471 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.471 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.474 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.475 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818475, latencyMs=25, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-14}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.475 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.475 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.476 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.476 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.476 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.476 [messageListenerContainer14-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.476 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.476 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@20c3296b)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.476 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.477 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.477 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.477 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.477 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.477 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.478 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.488 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer16' to allow for resolving potential circular references
2017-11-24 16:23:38.488 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer16'
2017-11-24 16:23:38.490 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.490 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.492 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.492 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.495 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.495 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.495 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.495 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.495 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.494 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.496 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.496 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.497 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.497 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.497 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.497 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.497 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer16'
2017-11-24 16:23:38.497 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer17'
2017-11-24 16:23:38.497 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer17'
2017-11-24 16:23:38.497 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory17'
2017-11-24 16:23:38.497 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties17'
2017-11-24 16:23:38.498 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer17' to allow for resolving potential circular references
2017-11-24 16:23:38.498 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer17'
2017-11-24 16:23:38.497 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.498 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.498 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.498 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.498 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.498 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.499 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.499 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.499 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.499 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.499 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.499 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.500 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.500 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.501 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.501 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.501 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.502 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.502 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer17'
2017-11-24 16:23:38.502 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer18'
2017-11-24 16:23:38.502 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer18'
2017-11-24 16:23:38.502 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory18'
2017-11-24 16:23:38.502 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties18'
2017-11-24 16:23:38.503 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.503 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer18' to allow for resolving potential circular references
2017-11-24 16:23:38.503 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer18'
2017-11-24 16:23:38.503 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818503, latencyMs=5, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-16}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.504 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.504 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.504 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.504 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.504 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.504 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.504 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.504 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.504 [messageListenerContainer16-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.504 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.504 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@1e813af0)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.504 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.505 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.505 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.505 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.505 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.505 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.505 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.505 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.506 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.506 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.507 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.508 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.508 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.508 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.508 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer18'
2017-11-24 16:23:38.508 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer19'
2017-11-24 16:23:38.508 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer19'
2017-11-24 16:23:38.508 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory19'
2017-11-24 16:23:38.508 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties19'
2017-11-24 16:23:38.508 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer19' to allow for resolving potential circular references
2017-11-24 16:23:38.509 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer19'
2017-11-24 16:23:38.509 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.509 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.509 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.509 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.510 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.510 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.510 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.510 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.510 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.510 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.512 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.512 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.512 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.512 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.512 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.512 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.512 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.512 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.512 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer19'
2017-11-24 16:23:38.512 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'messageListenerContainer20'
2017-11-24 16:23:38.512 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'messageListenerContainer20'
2017-11-24 16:23:38.512 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'consumerFactory20'
2017-11-24 16:23:38.512 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'containerProperties20'
2017-11-24 16:23:38.512 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.513 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.513 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'messageListenerContainer20' to allow for resolving potential circular references
2017-11-24 16:23:38.513 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.513 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.514 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Invoking init method  'doStart' on bean with name 'messageListenerContainer20'
2017-11-24 16:23:38.514 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.514 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:23:38.514 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Starting the Kafka consumer
2017-11-24 16:23:38.514 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.515 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.515 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.515 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.515 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.515 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.515 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.515 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818515, latencyMs=10, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-17}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.515 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.515 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@5c3e42af)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.516 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.517 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.517 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.517 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.517 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.517 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.518 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.152.45:9092 (id: -1 rack: null)], partitions = [])
2017-11-24 16:23:38.518 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
2017-11-24 16:23:38.519 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.519 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818519, latencyMs=6, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-18}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.519 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.519 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-11-24 16:23:38.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-11-24 16:23:38.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-11-24 16:23:38.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-11-24 16:23:38.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-11-24 16:23:38.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@3dd9cb12)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.520 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.521 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.521 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.522 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
2017-11-24 16:23:38.522 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:23:38.518 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.522 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Kafka consumer created
2017-11-24 16:23:38.522 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Subscribed to pattern: topic6
2017-11-24 16:23:38.522 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.523 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'messageListenerContainer20'
2017-11-24 16:23:38.523 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'producerProperties'
2017-11-24 16:23:38.523 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'producerProperties'
2017-11-24 16:23:38.523 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'producerProperties' to allow for resolving potential circular references
2017-11-24 16:23:38.523 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'producerProperties'
2017-11-24 16:23:38.523 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'producerFactory'
2017-11-24 16:23:38.523 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'producerFactory'
2017-11-24 16:23:38.524 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.524 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.524 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.524 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.524 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.524 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.525 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'producerProperties'
2017-11-24 16:23:38.525 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.525 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.527 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.527 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818527, latencyMs=5, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-19}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.527 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.527 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@a0f70a5)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.528 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.529 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.529 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.529 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.529 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.530 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'producerFactory' to allow for resolving potential circular references
2017-11-24 16:23:38.533 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.533 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.533 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending GroupCoordinator request for group 0 to broker 192.168.152.45:9092 (id: -1 rack: null)
2017-11-24 16:23:38.534 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 192.168.152.45:9092.
2017-11-24 16:23:38.534 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-11-24 16:23:38.535 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-11-24 16:23:38.535 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-11-24 16:23:38.535 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-11-24 16:23:38.535 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1.  Fetching API versions.
2017-11-24 16:23:38.535 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
2017-11-24 16:23:38.536 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.536 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -1
2017-11-24 16:23:38.537 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = wUTjXiY7R6i3peF4RJ_w5g, nodes = [192.168.152.45:9092 (id: 0 rack: null)], partitions = [Partition(topic = topic6, partition = 6, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 5, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 8, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 7, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 2, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 4, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 3, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 0, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 18, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 17, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 19, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 14, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 13, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 16, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 15, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 10, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 9, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 12, leader = 0, replicas = [0], isr = [0]), Partition(topic = topic6, partition = 11, leader = 0, replicas = [0], isr = [0])])
2017-11-24 16:23:38.538 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received GroupCoordinator response ClientResponse(receivedTimeMs=1511511818538, latencyMs=5, disconnected=false, requestHeader={api_key=10,api_version=1,correlation_id=0,client_id=consumer-20}, responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=192.168.152.45:9092 (id: 0 rack: null))) for group 0
2017-11-24 16:23:38.538 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:23:38.538 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 2147483647 at 192.168.152.45:9092.
2017-11-24 16:23:38.538 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@3e9b618a)) to coordinator 192.168.152.45:9092 (id: 2147483647 rack: null)
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 2147483647.  Fetching API versions.
2017-11-24 16:23:38.539 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 2147483647.
2017-11-24 16:23:38.540 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 2147483647: (Produce(0): 0 to 3 [usable: 3], Fetch(1): 0 to 5 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 4 [usable: 4], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0])
2017-11-24 16:23:38.541 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'producerFactory'
2017-11-24 16:23:38.541 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'KafkaTemplate'
2017-11-24 16:23:38.541 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'KafkaTemplate'
2017-11-24 16:23:38.542 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.543 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 started
2017-11-24 16:23:38.544 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'producerFactory'
2017-11-24 16:23:38.550 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Eagerly caching bean 'KafkaTemplate' to allow for resolving potential circular references
2017-11-24 16:23:38.553 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'KafkaTemplate'
2017-11-24 16:23:38.553 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'org.mybatis.spring.mapper.MapperScannerConfigurer#1'
2017-11-24 16:23:38.553 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractDao'
2017-11-24 16:23:38.554 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.context.support.GenericApplicationContext - Unable to locate LifecycleProcessor with name 'lifecycleProcessor': using default [org.springframework.context.support.DefaultLifecycleProcessor@2dd29a59]
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer2'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer3'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer4'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer5'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer6'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer7'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer8'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer9'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer10'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer11'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer12'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer13'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer14'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer15'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer16'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer17'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer18'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer19'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer20'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'producerFactory'
2017-11-24 16:23:38.581 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'lifecycleProcessor'
2017-11-24 16:23:38.585 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-24 16:23:38.587 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'sqlSessionFactory'
2017-11-24 16:23:38.588 [main] DEBUG org.springframework.core.env.PropertySourcesPropertyResolver - Could not find key 'spring.liveBeansView.mbeanDomain' in any property source
2017-11-24 16:23:38.590 [main] DEBUG org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate - Storing ApplicationContext in cache under key [[MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]]]
2017-11-24 16:23:38.590 [main] DEBUG org.springframework.test.context.cache - Spring test ApplicationContext cache statistics: [DefaultContextCache@4097cac size = 1, maxSize = 32, parentContextCount = 0, hitCount = 0, missCount = 1]
2017-11-24 16:23:38.592 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for org.dao.ExtractDao ExtractTest.extractDao
2017-11-24 16:23:38.592 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.592 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractDao'
2017-11-24 16:23:38.593 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'ExtractTest' to bean named 'extractDao'
2017-11-24 16:23:38.593 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for private org.springframework.kafka.core.KafkaTemplate ExtractTest.kafkaTemplate
2017-11-24 16:23:38.593 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.594 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'KafkaTemplate'
2017-11-24 16:23:38.594 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'ExtractTest' to bean named 'KafkaTemplate'
2017-11-24 16:23:38.594 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for org.service.ExtractService ExtractTest.extractService
2017-11-24 16:23:38.594 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.594 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.594 [main] DEBUG o.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor - Autowiring by type from bean name 'ExtractTest' to bean named 'extractServiceImpl'
2017-11-24 16:23:38.598 [main] DEBUG o.s.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test method: context [DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@11c20519, testMethod = testExtract@ExtractTest, testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null], method annotated with @DirtiesContext [false] with mode [null].
2017-11-24 16:23:38.603 [main] DEBUG o.s.test.context.support.AbstractDirtiesContextTestExecutionListener - After test method: context [DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@11c20519, testMethod = testExtract@ExtractTest, testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null], method annotated with @DirtiesContext [false] with mode [null].
2017-11-24 16:23:38.603 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [ExtractTest]
2017-11-24 16:23:38.603 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [ExtractTest]
2017-11-24 16:23:38.603 [main] DEBUG o.springframework.test.context.support.DependencyInjectionTestExecutionListener - Performing dependency injection for test context [[DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@5ddea849, testMethod = [null], testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]]].
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate - Retrieved ApplicationContext from cache with key [[MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]]]
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.test.context.cache - Spring test ApplicationContext cache statistics: [DefaultContextCache@4097cac size = 1, maxSize = 32, parentContextCount = 0, hitCount = 1, missCount = 1]
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for org.dao.ExtractDao ExtractTest.extractDao
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractDao'
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for private org.springframework.kafka.core.KafkaTemplate ExtractTest.kafkaTemplate
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'KafkaTemplate'
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for org.service.ExtractService ExtractTest.extractService
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.604 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.605 [main] DEBUG o.s.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test method: context [DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@5ddea849, testMethod = testExtract2@ExtractTest, testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null], method annotated with @DirtiesContext [false] with mode [null].
2017-11-24 16:23:38.605 [main] DEBUG o.s.test.context.support.AbstractDirtiesContextTestExecutionListener - After test method: context [DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@5ddea849, testMethod = testExtract2@ExtractTest, testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null], method annotated with @DirtiesContext [false] with mode [null].
2017-11-24 16:23:38.605 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [ExtractTest]
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [ExtractTest]
2017-11-24 16:23:38.606 [main] DEBUG o.springframework.test.context.support.DependencyInjectionTestExecutionListener - Performing dependency injection for test context [[DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@5ee2b6f9, testMethod = [null], testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]]].
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate - Retrieved ApplicationContext from cache with key [[MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]]]
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.test.context.cache - Spring test ApplicationContext cache statistics: [DefaultContextCache@4097cac size = 1, maxSize = 32, parentContextCount = 0, hitCount = 2, missCount = 1]
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for org.dao.ExtractDao ExtractTest.extractDao
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractDao'
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for private org.springframework.kafka.core.KafkaTemplate ExtractTest.kafkaTemplate
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'KafkaTemplate'
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.beans.factory.annotation.InjectionMetadata - Processing injected element of bean 'ExtractTest': AutowiredFieldElement for org.service.ExtractService ExtractTest.extractService
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.core.annotation.AnnotationUtils - Failed to meta-introspect annotation [interface org.springframework.beans.factory.annotation.Autowired]: java.lang.IllegalArgumentException: Annotation must not be null
2017-11-24 16:23:38.606 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'extractServiceImpl'
2017-11-24 16:23:38.606 [main] DEBUG o.s.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test method: context [DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@5ee2b6f9, testMethod = producerTestSimple@ExtractTest, testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null], method annotated with @DirtiesContext [false] with mode [null].
2017-11-24 16:23:38.607 [main] DEBUG o.s.test.context.support.AbstractDirtiesContextTestExecutionListener - After test method: context [DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = ExtractTest@5ee2b6f9, testMethod = producerTestSimple@ExtractTest, testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null], method annotated with @DirtiesContext [false] with mode [null].
2017-11-24 16:23:38.608 [main] DEBUG o.s.test.context.support.AbstractDirtiesContextTestExecutionListener - After test class: context [DefaultTestContext@5cdd8682 testClass = ExtractTest, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d6da883 testClass = ExtractTest, locations = '{classpath*:spring/*.xml}', classes = '{}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{}', contextCustomizers = set[[empty]], contextLoader = 'org.springframework.test.context.support.DelegatingSmartContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null].
2017-11-24 16:23:38.612 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 16:23:37 CST 2017]; root of context hierarchy
2017-11-24 16:23:38.613 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'sqlSessionFactory'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer2'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer3'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer4'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer5'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer6'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer7'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer8'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer9'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer10'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer11'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer12'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer13'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer14'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer15'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer16'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer17'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer18'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer19'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'messageListenerContainer20'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'producerFactory'
2017-11-24 16:23:38.615 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'lifecycleProcessor'
2017-11-24 16:23:38.629 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-24 16:23:38.629 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.631 [messageListenerContainer-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.631 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.631 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.631 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer2' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.634 [messageListenerContainer2-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.634 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.634 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.634 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer3' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.634 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer4' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.634 [messageListenerContainer3-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.634 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.634 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.634 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer5' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.635 [messageListenerContainer4-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.635 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.635 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.635 [messageListenerContainer5-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.635 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.635 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.635 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer6' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.635 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer7' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.635 [messageListenerContainer6-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.635 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.635 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.635 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer8' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.635 [messageListenerContainer7-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.635 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.635 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.635 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer9' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.635 [messageListenerContainer8-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.635 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.635 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.635 [messageListenerContainer9-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.635 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer10' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.635 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.635 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.636 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer11' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.636 [messageListenerContainer10-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.636 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.636 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.636 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer12' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.636 [messageListenerContainer11-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.636 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.636 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.636 [messageListenerContainer12-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.636 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.636 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer13' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.636 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.636 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer14' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.636 [messageListenerContainer13-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.636 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.636 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.636 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer15' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.636 [messageListenerContainer14-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.636 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.636 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.636 [messageListenerContainer15-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.636 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.637 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.637 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer16' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.637 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer17' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.637 [messageListenerContainer16-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.637 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.637 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.637 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer18' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.637 [messageListenerContainer17-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.637 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.637 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.637 [messageListenerContainer18-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.637 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.637 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.637 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer19' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.637 [messageListenerContainer19-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.637 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.637 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.637 [Thread-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Asking bean 'messageListenerContainer20' of type [class org.springframework.kafka.listener.KafkaMessageListenerContainer] to stop
2017-11-24 16:23:38.637 [messageListenerContainer20-C-1] DEBUG o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
2017-11-24 16:23:38.638 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - Unsubscribed all topics or patterns and assigned partitions
2017-11-24 16:23:38.638 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Sending synchronous auto-commit of offsets {} for group 0
2017-11-24 16:23:38.638 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.638 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.638 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.638 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.638 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.640 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.640 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.639 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:38.640 [kafka-coordinator-heartbeat-thread | 0] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Heartbeat thread for group 0 has closed
2017-11-24 16:23:58.207 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@4aa19407
2017-11-24 16:23:58.207 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@3c0a65e8
2017-11-24 16:23:58.209 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@6a2971c4
2017-11-24 16:23:58.210 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@48b4cd12
2017-11-24 16:23:58.210 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@3134c0d2
2017-11-24 16:23:58.212 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.212 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.212 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.213 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.213 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.213 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.213 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@5bc3697
2017-11-24 16:23:58.213 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@465c63ed
2017-11-24 16:23:58.215 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@6ed6b6bf
2017-11-24 16:23:58.216 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@df13f5c
2017-11-24 16:23:58.217 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.217 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.217 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.217 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.218 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.218 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.218 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.218 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.218 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.218 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.219 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.219 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.219 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@4d6e0df2
2017-11-24 16:23:58.219 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.219 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@3fea9e59
2017-11-24 16:23:58.219 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.219 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@30d6b841
2017-11-24 16:23:58.220 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@350c61c1
2017-11-24 16:23:58.221 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@46e88d7e
2017-11-24 16:23:58.221 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@69e37480
2017-11-24 16:23:58.221 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@42afa744
2017-11-24 16:23:58.222 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.222 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.222 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.223 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.223 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.223 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.223 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.223 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.223 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.223 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.207 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@76255150
2017-11-24 16:23:58.224 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.224 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.224 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.224 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.225 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.225 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.225 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.225 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@33c36dc3
2017-11-24 16:23:58.225 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.225 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.225 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.226 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.213 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@3d00b13
2017-11-24 16:23:58.226 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.226 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.213 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.227 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.226 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Received successful JoinGroup response for group 0: org.apache.kafka.common.requests.JoinGroupResponse@31f3591c
2017-11-24 16:23:58.227 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.227 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.227 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.226 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.228 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.228 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.228 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.228 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.228 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.229 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.229 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.229 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.229 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.229 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.229 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.229 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.229 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.229 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.229 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.229 [messageListenerContainer11-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.229 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.229 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.229 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.230 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.230 [messageListenerContainer11-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer11, topicPartitions=null] stopped normally
2017-11-24 16:23:58.230 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.230 [messageListenerContainer11-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer11' completed its stop procedure
2017-11-24 16:23:58.230 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.230 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.230 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.230 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.230 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.230 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.230 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.230 [messageListenerContainer5-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.230 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.230 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.230 [messageListenerContainer5-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer5, topicPartitions=null] stopped normally
2017-11-24 16:23:58.230 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.230 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.230 [messageListenerContainer5-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer5' completed its stop procedure
2017-11-24 16:23:58.230 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.230 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.231 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.231 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.231 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.231 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.231 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.231 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.231 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.231 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.231 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.231 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.231 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.231 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.231 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.231 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.231 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.231 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.232 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.232 [messageListenerContainer-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.232 [messageListenerContainer-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.232 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer12, topicPartitions=null] stopped normally
2017-11-24 16:23:58.232 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.232 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.232 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.232 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.232 [messageListenerContainer-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer, topicPartitions=null] stopped normally
2017-11-24 16:23:58.232 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.232 [messageListenerContainer-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer' completed its stop procedure
2017-11-24 16:23:58.233 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.233 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.233 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.233 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.233 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.233 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.232 [messageListenerContainer12-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer12' completed its stop procedure
2017-11-24 16:23:58.233 [messageListenerContainer18-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.233 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.233 [messageListenerContainer18-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer18, topicPartitions=null] stopped normally
2017-11-24 16:23:58.233 [messageListenerContainer18-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer18' completed its stop procedure
2017-11-24 16:23:58.233 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.233 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.233 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.233 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.234 [messageListenerContainer13-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.234 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.234 [messageListenerContainer13-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer13, topicPartitions=null] stopped normally
2017-11-24 16:23:58.234 [messageListenerContainer13-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer13' completed its stop procedure
2017-11-24 16:23:58.234 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.234 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.234 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.234 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.234 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.234 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.234 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.234 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.234 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.235 [messageListenerContainer17-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.235 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.235 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.235 [messageListenerContainer17-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer17, topicPartitions=null] stopped normally
2017-11-24 16:23:58.235 [messageListenerContainer17-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer17' completed its stop procedure
2017-11-24 16:23:58.235 [messageListenerContainer14-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.235 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.235 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.235 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.235 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.235 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.235 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.235 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.235 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.235 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.235 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.235 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.235 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.235 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.235 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.235 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.235 [messageListenerContainer14-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer14, topicPartitions=null] stopped normally
2017-11-24 16:23:58.236 [messageListenerContainer14-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer14' completed its stop procedure
2017-11-24 16:23:58.235 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.236 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.236 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.236 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.236 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.236 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.236 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.236 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.236 [messageListenerContainer2-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.236 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.236 [messageListenerContainer2-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer2, topicPartitions=null] stopped normally
2017-11-24 16:23:58.236 [messageListenerContainer2-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer2' completed its stop procedure
2017-11-24 16:23:58.236 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.236 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.236 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.236 [messageListenerContainer3-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.236 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.236 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.237 [messageListenerContainer3-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer3, topicPartitions=null] stopped normally
2017-11-24 16:23:58.237 [messageListenerContainer7-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.237 [messageListenerContainer3-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer3' completed its stop procedure
2017-11-24 16:23:58.237 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.237 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.237 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.237 [messageListenerContainer7-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer7, topicPartitions=null] stopped normally
2017-11-24 16:23:58.237 [messageListenerContainer19-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.237 [messageListenerContainer7-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer7' completed its stop procedure
2017-11-24 16:23:58.237 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.237 [messageListenerContainer19-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer19, topicPartitions=null] stopped normally
2017-11-24 16:23:58.237 [messageListenerContainer19-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer19' completed its stop procedure
2017-11-24 16:23:58.238 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.238 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.238 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.238 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.238 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.238 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.238 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.238 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.238 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.238 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.238 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.238 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.238 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.239 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.239 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.239 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.239 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.239 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.239 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.239 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.239 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.239 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.239 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.239 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.239 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.239 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.239 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.239 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.239 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.239 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.239 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.239 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.239 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.240 [messageListenerContainer4-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.240 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.240 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.240 [messageListenerContainer4-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer4, topicPartitions=null] stopped normally
2017-11-24 16:23:58.240 [messageListenerContainer4-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer4' completed its stop procedure
2017-11-24 16:23:58.240 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.240 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.240 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.240 [messageListenerContainer20-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.240 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.240 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.240 [messageListenerContainer20-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer20, topicPartitions=null] stopped normally
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.240 [messageListenerContainer20-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer20' completed its stop procedure
2017-11-24 16:23:58.240 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.240 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.240 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.240 [messageListenerContainer16-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.241 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.241 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.241 [messageListenerContainer16-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer16, topicPartitions=null] stopped normally
2017-11-24 16:23:58.241 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.241 [messageListenerContainer16-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer16' completed its stop procedure
2017-11-24 16:23:58.241 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.241 [messageListenerContainer10-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.241 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.241 [messageListenerContainer10-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer10, topicPartitions=null] stopped normally
2017-11-24 16:23:58.241 [messageListenerContainer10-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer10' completed its stop procedure
2017-11-24 16:23:58.241 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.241 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.241 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.241 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.241 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.242 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.242 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.242 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.242 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.242 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.242 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.242 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.242 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.242 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer8, topicPartitions=null] stopped normally
2017-11-24 16:23:58.243 [messageListenerContainer8-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer8' completed its stop procedure
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.244 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.244 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.244 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.244 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.244 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.244 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
2017-11-24 16:23:58.244 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.244 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.245 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.245 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
2017-11-24 16:23:58.245 [messageListenerContainer15-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.245 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.245 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.245 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.245 [messageListenerContainer15-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer15, topicPartitions=null] stopped normally
2017-11-24 16:23:58.245 [messageListenerContainer15-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer15' completed its stop procedure
2017-11-24 16:23:58.245 [messageListenerContainer9-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.245 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.245 [messageListenerContainer9-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer9, topicPartitions=null] stopped normally
2017-11-24 16:23:58.245 [messageListenerContainer9-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer9' completed its stop procedure
2017-11-24 16:23:58.245 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
2017-11-24 16:23:58.245 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
2017-11-24 16:23:58.245 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
2017-11-24 16:23:58.245 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
2017-11-24 16:23:58.245 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
2017-11-24 16:23:58.245 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
2017-11-24 16:23:58.246 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
2017-11-24 16:23:58.246 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
2017-11-24 16:23:58.246 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
2017-11-24 16:23:58.246 [messageListenerContainer6-C-1] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - The Kafka consumer has closed.
2017-11-24 16:23:58.246 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:23:58.246 [messageListenerContainer6-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer - KafkaMessageListenerContainer [id=messageListenerContainer6, topicPartitions=null] stopped normally
2017-11-24 16:23:58.246 [messageListenerContainer6-C-1] DEBUG org.springframework.context.support.DefaultLifecycleProcessor - Bean 'messageListenerContainer6' completed its stop procedure
2017-11-24 16:23:58.246 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@694abbdc: defining beans [extractServiceImpl,org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,propertyConfigurer,transactionManager,dataSource,sqlSessionFactory,org.mybatis.spring.mapper.MapperScannerConfigurer#0,consumer1,consumerFactory1,consumerFactory2,consumerFactory3,consumerFactory4,consumerFactory5,consumerFactory6,consumerFactory7,consumerFactory8,consumerFactory9,consumerFactory10,consumerFactory11,consumerFactory12,consumerFactory13,consumerFactory14,consumerFactory15,consumerFactory16,consumerFactory17,consumerFactory18,consumerFactory19,consumerFactory20,messageListernerConsumerService,messageListernerConsumerService2,messageListernerConsumerService3,messageListernerConsumerService4,messageListernerConsumerService5,messageListernerConsumerService6,messageListernerConsumerService7,messageListernerConsumerService8,messageListernerConsumerService9,messageListernerConsumerService10,messageListernerConsumerService11,messageListernerConsumerService12,messageListernerConsumerService13,messageListernerConsumerService14,messageListernerConsumerService15,messageListernerConsumerService16,messageListernerConsumerService17,messageListernerConsumerService18,messageListernerConsumerService19,messageListernerConsumerService20,containerProperties1,containerProperties2,containerProperties3,containerProperties4,containerProperties5,containerProperties6,containerProperties7,containerProperties8,containerProperties9,containerProperties10,containerProperties11,containerProperties12,containerProperties13,containerProperties14,containerProperties15,containerProperties16,containerProperties17,containerProperties18,containerProperties19,containerProperties20,messageListenerContainer,messageListenerContainer2,messageListenerContainer3,messageListenerContainer4,messageListenerContainer5,messageListenerContainer6,messageListenerContainer7,messageListenerContainer8,messageListenerContainer9,messageListenerContainer10,messageListenerContainer11,messageListenerContainer12,messageListenerContainer13,messageListenerContainer14,messageListenerContainer15,messageListenerContainer16,messageListenerContainer17,messageListenerContainer18,messageListenerContainer19,messageListenerContainer20,producerProperties,producerFactory,KafkaTemplate,org.mybatis.spring.mapper.MapperScannerConfigurer#1,extractDao]; root of factory hierarchy
2017-11-24 16:23:58.246 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'producerFactory': [KafkaTemplate]
2017-11-24 16:23:58.246 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'KafkaTemplate': [ExtractTest]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DisposableBeanAdapter - Invoking destroy() on bean with name 'producerFactory'
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'sqlSessionFactory': [extractDao]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'extractDao': [extractServiceImpl]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'extractServiceImpl': [messageListernerConsumerService, messageListernerConsumerService2, messageListernerConsumerService3, messageListernerConsumerService4, messageListernerConsumerService5, messageListernerConsumerService6, messageListernerConsumerService7, messageListernerConsumerService8, messageListernerConsumerService9, messageListernerConsumerService10, messageListernerConsumerService11, messageListernerConsumerService12, messageListernerConsumerService13, messageListernerConsumerService14, messageListernerConsumerService15, messageListernerConsumerService16, messageListernerConsumerService17, messageListernerConsumerService18, messageListernerConsumerService19, messageListernerConsumerService20]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService': [containerProperties1]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties1': [messageListenerContainer]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService2': [containerProperties2]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties2': [messageListenerContainer2]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService3': [containerProperties3]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties3': [messageListenerContainer3]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService4': [containerProperties4]
2017-11-24 16:23:58.247 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties4': [messageListenerContainer4]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService5': [containerProperties5]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties5': [messageListenerContainer5]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService6': [containerProperties6]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties6': [messageListenerContainer6]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService7': [containerProperties7]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties7': [messageListenerContainer7]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService8': [containerProperties8]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties8': [messageListenerContainer8]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService9': [containerProperties9]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties9': [messageListenerContainer9]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService10': [containerProperties10]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties10': [messageListenerContainer10]
2017-11-24 16:23:58.251 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService11': [containerProperties11]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties11': [messageListenerContainer11]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService12': [containerProperties12]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties12': [messageListenerContainer12]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService13': [containerProperties13]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties13': [messageListenerContainer13]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService14': [containerProperties14]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties14': [messageListenerContainer14]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService15': [containerProperties15]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties15': [messageListenerContainer15]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService16': [containerProperties16]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties16': [messageListenerContainer16]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService17': [containerProperties17]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties17': [messageListenerContainer17]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService18': [containerProperties18]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties18': [messageListenerContainer18]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService19': [containerProperties19]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties19': [messageListenerContainer19]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'messageListernerConsumerService20': [containerProperties20]
2017-11-24 16:23:58.252 [Thread-1] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Retrieved dependent beans for bean 'containerProperties20': [messageListenerContainer20]
2017-11-24 16:30:42.857 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-24 16:30:42.863 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-24 16:30:42.871 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-24 16:30:42.926 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-24 16:30:43.060 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 16:30:43.078 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 16:30:43.120 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 16:30:43.133 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 16:30:43.167 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 16:30:43.179 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 16:30:43.191 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 16:30:43 CST 2017]; root of context hierarchy
2017-11-24 16:30:43.339 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-24 16:30:43.339 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-24 16:30:44.013 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.073 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.073 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.079 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.083 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.083 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.085 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.089 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.089 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.090 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.099 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.099 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.100 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.104 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.104 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.106 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.109 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.109 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.111 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.119 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.120 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.121 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.125 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.125 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.127 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.132 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.132 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.134 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.137 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.137 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.138 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.141 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.141 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.143 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.146 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.146 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.147 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.150 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.150 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.152 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.160 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.160 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.160 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.160 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.160 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.160 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.161 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.163 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.163 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.163 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.163 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.163 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.163 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.163 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.163 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.163 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.163 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.163 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.163 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.163 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.163 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.163 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.163 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.163 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.164 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.164 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.164 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.163 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.170 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.170 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.171 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.172 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.172 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.172 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.172 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.172 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.172 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.173 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.174 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.174 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.175 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.175 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.177 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.177 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.178 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.178 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.178 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.178 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.178 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.178 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.178 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.181 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.181 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.184 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.185 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.185 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.185 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.186 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.187 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.187 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.187 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.190 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.190 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.190 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.190 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.193 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.200 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.200 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.202 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.204 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.204 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.204 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.205 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.205 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.205 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.206 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.208 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.209 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.209 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.210 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.210 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.210 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.210 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.213 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.213 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.213 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.213 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.213 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.213 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.214 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 16:30:44.218 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 16:30:44.218 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.218 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 16:30:44.218 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.219 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.219 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.223 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 16:30:44.224 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 16:30:44.224 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 16:30:44.224 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 16:30:44.264 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-24 16:30:44.281 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 16:30:43 CST 2017]; root of context hierarchy
2017-11-24 16:30:44.283 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-24 16:30:46.932 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.932 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.931 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.935 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.935 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.936 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.936 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.936 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.937 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.937 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.938 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.938 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.938 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.938 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.939 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.940 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.940 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.940 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.940 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 16:30:46.942 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:01.451 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-24 17:12:01.456 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-24 17:12:01.463 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-24 17:12:01.519 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-24 17:12:01.656 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 17:12:01.675 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 17:12:01.708 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 17:12:01.723 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 17:12:01.758 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 17:12:01.767 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 17:12:01.784 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 17:12:01 CST 2017]; root of context hierarchy
2017-11-24 17:12:01.925 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-24 17:12:01.925 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-24 17:12:02.589 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.641 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.641 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.646 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.651 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.651 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.653 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.659 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.659 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.660 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.666 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.666 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.668 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.676 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.676 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.677 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.682 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.682 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.684 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.691 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.691 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.693 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.695 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.696 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.698 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.702 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.702 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.703 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.708 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.708 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.711 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.713 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.714 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.715 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.718 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.718 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.719 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.723 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.723 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.725 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.732 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.733 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.733 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.732 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.732 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.733 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.733 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.735 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.733 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.735 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.735 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.735 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.735 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.735 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.736 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.736 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.736 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.736 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.736 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.736 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.736 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.736 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.736 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.736 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.736 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.736 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.736 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.736 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.736 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.736 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.737 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.737 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.737 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.735 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.737 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.737 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.737 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.737 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.738 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.738 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.738 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.739 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.739 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.739 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.750 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.750 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.750 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.751 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.751 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.751 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.752 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.753 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.754 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.754 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.754 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.755 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.756 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.756 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.756 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.756 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.755 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.761 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.762 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.762 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.762 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.764 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.767 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.767 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.769 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.772 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.772 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.772 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.773 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.773 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.773 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.774 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.776 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.777 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.777 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.778 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.778 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.778 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.778 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.780 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.780 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.780 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.780 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.780 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.780 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.781 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:12:02.784 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.784 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.784 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.784 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.788 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:12:02.788 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:12:02.793 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:12:02.794 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:12:02.794 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:12:02.794 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:12:02.832 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-24 17:12:02.856 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 17:12:01 CST 2017]; root of context hierarchy
2017-11-24 17:12:02.859 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-24 17:12:06.127 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.129 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.131 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.133 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.134 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.139 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.142 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.144 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.148 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.150 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.150 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.150 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.151 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.151 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.151 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.152 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.152 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.153 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.153 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:12:06.154 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:18.897 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-24 17:23:18.902 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-24 17:23:18.910 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-24 17:23:18.997 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-24 17:23:19.134 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 17:23:19.151 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 17:23:19.187 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 17:23:19.199 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 17:23:19.229 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 17:23:19.241 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 17:23:19.257 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 17:23:19 CST 2017]; root of context hierarchy
2017-11-24 17:23:19.402 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-24 17:23:19.402 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-24 17:23:20.122 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.178 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.179 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.184 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.192 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.192 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.194 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.200 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.200 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.202 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.209 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.209 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.210 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.215 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.215 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.217 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.220 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.220 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.221 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.229 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.229 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.230 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.236 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.237 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.239 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.243 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.243 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.245 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.251 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.251 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.253 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.256 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.257 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.258 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.261 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.261 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.262 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.271 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.271 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.274 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.274 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.274 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.274 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.275 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.275 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.275 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.275 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.275 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.275 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.275 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.275 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.275 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.276 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.279 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.280 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.280 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.280 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.281 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.281 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.281 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.282 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.283 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.282 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.284 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.284 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.284 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.284 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.284 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.286 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.287 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.288 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.289 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.290 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.290 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.290 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.290 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.290 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.291 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.292 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.292 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.292 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.294 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.294 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.294 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.295 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.296 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.296 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.296 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.297 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.297 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.297 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.297 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.297 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.297 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.301 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.301 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.301 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.302 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.307 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.307 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.308 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.309 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.309 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.309 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.311 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.311 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.312 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.312 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.315 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.318 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.318 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.318 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.319 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.319 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.319 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.319 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.321 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.321 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.322 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.323 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.323 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.323 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.323 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.324 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.325 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.325 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.325 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.325 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.325 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.327 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:23:20.329 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.330 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.330 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.330 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.333 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:23:20.333 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:23:20.338 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:23:20.339 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:23:20.339 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:23:20.339 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:23:20.379 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-24 17:23:20.405 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 17:23:19 CST 2017]; root of context hierarchy
2017-11-24 17:23:20.407 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-24 17:23:24.613 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.613 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.614 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.615 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.621 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.622 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.623 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.623 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.624 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.624 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.624 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.626 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.626 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.627 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.627 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.629 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.630 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.630 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.631 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:23:24.638 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:27.141 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-24 17:39:27.147 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-24 17:39:27.155 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-24 17:39:27.234 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-24 17:39:27.376 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 17:39:27.394 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 17:39:27.430 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 17:39:27.448 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 17:39:27.481 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 17:39:27.493 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 17:39:27.508 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 17:39:27 CST 2017]; root of context hierarchy
2017-11-24 17:39:27.659 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-24 17:39:27.659 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-24 17:39:28.332 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.385 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.385 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.390 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.396 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.396 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.398 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.405 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.406 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.407 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.410 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.410 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.413 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.418 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.418 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.420 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.425 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.425 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.427 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.431 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.431 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.432 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.438 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.438 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.439 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.443 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.443 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.445 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.447 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.448 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.449 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.452 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.452 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.454 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.456 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.456 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.459 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.463 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.463 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.465 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.467 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.467 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.468 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.477 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.478 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.476 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.476 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.476 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.476 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.480 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.479 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.481 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.481 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.481 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.481 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.481 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.481 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.481 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.481 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.481 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.481 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.481 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.481 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.482 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.482 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.482 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.479 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.485 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.486 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.486 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.486 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.486 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.486 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.487 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.488 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.488 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.489 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.489 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.489 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.489 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.489 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.489 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.488 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.490 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.490 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.492 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.494 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.494 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.494 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.494 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.494 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.494 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.495 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.496 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.497 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.497 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.497 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.503 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.504 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.505 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.505 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.505 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.507 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.507 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.508 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.511 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.511 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.511 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.511 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.511 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.511 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.513 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.514 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.515 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.515 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.515 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.516 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.517 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.517 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.517 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.518 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.518 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.519 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.521 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.521 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.521 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.522 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.522 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.522 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.522 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 17:39:28.525 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.525 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.525 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.525 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.526 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 17:39:28.527 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 17:39:28.533 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 17:39:28.534 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 17:39:28.534 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 17:39:28.534 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 17:39:28.573 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-24 17:39:28.591 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 17:39:27 CST 2017]; root of context hierarchy
2017-11-24 17:39:28.593 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-24 17:39:31.547 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.549 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.553 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.559 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.560 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.562 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.563 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.564 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.566 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.569 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.569 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.570 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.571 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.571 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.572 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.574 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.574 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.575 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.575 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 17:39:31.576 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:22:58.163 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-24 18:22:58.168 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-24 18:22:58.176 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-24 18:22:58.240 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-24 18:22:58.400 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 18:22:58.421 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 18:22:58.464 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 18:22:58.480 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 18:22:58.522 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 18:22:58.549 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 18:22:58.571 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 18:22:58 CST 2017]; root of context hierarchy
2017-11-24 18:22:58.755 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-24 18:22:58.755 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-24 18:22:59.632 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.695 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.695 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.700 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.706 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.707 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.708 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.713 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.713 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.715 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.722 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.722 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.723 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.729 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.730 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.731 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.737 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.737 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.739 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.746 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.747 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.751 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.756 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.756 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.758 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.762 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.762 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.764 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.766 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.766 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.768 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.773 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.773 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.774 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.776 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.783 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.786 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.784 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.786 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.785 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.788 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.788 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.789 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.789 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.789 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.789 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.789 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.784 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.789 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.788 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.789 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.789 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.789 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.789 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.789 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.789 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.789 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.789 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.790 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.790 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.790 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.790 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.790 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.777 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.796 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.797 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.798 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.798 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.798 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.799 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.799 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.799 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.801 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.802 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.802 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.802 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.794 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.806 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.806 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.806 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.806 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.809 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.810 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.811 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.812 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.813 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.813 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.813 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.813 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.814 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.814 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.814 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.814 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.814 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.817 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.819 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.819 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.820 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.820 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.820 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.820 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.826 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.827 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.827 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.828 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.832 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.835 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.835 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.836 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.838 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.838 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.839 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.839 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.839 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.839 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.839 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.843 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.843 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.844 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.845 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.845 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.845 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.845 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.846 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.846 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.846 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.846 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.847 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.847 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.847 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:22:59.850 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.850 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.850 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.850 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.851 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:22:59.851 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:22:59.857 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:22:59.858 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:22:59.858 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:22:59.858 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:22:59.897 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-24 18:22:59.915 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 18:22:58 CST 2017]; root of context hierarchy
2017-11-24 18:22:59.917 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-24 18:23:02.230 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.233 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.234 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.237 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.244 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.244 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.245 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.246 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.247 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.248 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.248 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.249 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.250 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.251 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.251 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.251 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.252 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.252 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.252 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:23:02.252 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:46.015 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-24 18:25:46.020 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-24 18:25:46.029 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-24 18:25:46.084 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-24 18:25:46.230 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 18:25:46.247 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 18:25:46.283 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 18:25:46.295 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-24 18:25:46.336 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-24 18:25:46.349 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-24 18:25:46.367 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 18:25:46 CST 2017]; root of context hierarchy
2017-11-24 18:25:46.518 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-24 18:25:46.518 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-24 18:25:47.193 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.244 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.244 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.249 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.255 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.255 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.258 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.263 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.263 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.264 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.271 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.271 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.273 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.281 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.282 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.286 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.299 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.299 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.302 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.306 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.306 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.310 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.316 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.316 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.317 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.320 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.320 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.321 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.324 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.324 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.325 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.331 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.332 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.333 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.336 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.336 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.338 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.341 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.341 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.342 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.352 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.352 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.354 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.354 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.354 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.354 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.354 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.354 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.357 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.357 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.357 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.357 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.357 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.357 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.357 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.357 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.357 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.357 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.357 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.357 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.357 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.357 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.357 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.357 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.357 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.357 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.357 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.357 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.358 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.358 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.358 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.359 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.359 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.360 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.361 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.361 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.361 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.361 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.361 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.361 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.361 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.367 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.367 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.367 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.367 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.359 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.361 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.369 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.370 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.370 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.370 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.370 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.371 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.371 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.371 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.372 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.372 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.376 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.377 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.377 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.377 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.382 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.383 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.383 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.383 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.385 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.388 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.388 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.390 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.393 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.393 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.394 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.395 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.395 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.395 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.396 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.398 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.398 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.399 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.399 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.399 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.400 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.400 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.402 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.402 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.402 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.402 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.402 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.403 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.403 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-24 18:25:47.406 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.407 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.407 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.407 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.412 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-24 18:25:47.412 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-24 18:25:47.416 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-24 18:25:47.417 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-24 18:25:47.417 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-24 18:25:47.417 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-24 18:25:47.458 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-24 18:25:47.477 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Fri Nov 24 18:25:46 CST 2017]; root of context hierarchy
2017-11-24 18:25:47.478 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-24 18:25:47.649 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.652 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.656 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.666 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.671 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.672 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.673 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.673 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.676 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.676 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.676 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.677 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.677 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.678 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.678 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.678 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.679 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.680 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.680 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-24 18:25:47.681 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 09:58:19.230 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-27 09:58:19.273 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-27 09:58:19.300 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-27 09:58:19.590 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-27 09:58:20.295 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 09:58:20.320 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 09:58:20.336 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 09:58:20.352 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 09:58:20.385 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 09:58:20.394 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 09:58:20.397 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 09:58:20 CST 2017]; root of context hierarchy
2017-11-27 09:58:20.931 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-27 09:58:20.931 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-27 09:58:23.198 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [172.16.247.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 09:58:23.502 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 09:58:23.502 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 09:58:23.533 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [172.16.247.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 09:58:23.533 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 09:58:23.533 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 09:58:23.699 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-27 09:58:23.730 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 09:58:20 CST 2017]; root of context hierarchy
2017-11-27 09:58:23.767 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-27 09:58:23.772 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 09:58:23.772 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 10:06:25.745 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-27 10:06:25.750 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-27 10:06:25.758 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-27 10:06:25.809 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-27 10:06:25.949 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 10:06:25.966 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 10:06:25.990 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 10:06:26.003 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 10:06:26.024 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 10:06:26.036 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 10:06:26.051 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 10:06:26 CST 2017]; root of context hierarchy
2017-11-27 10:06:26.182 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-27 10:06:26.182 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-27 10:06:26.814 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 10:06:26.864 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 10:06:26.864 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 10:06:26.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 10:06:26.873 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 10:06:26.873 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 10:06:26.956 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-27 10:06:26.974 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 10:06:26 CST 2017]; root of context hierarchy
2017-11-27 10:06:26.976 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-27 10:06:26.984 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 10:06:26.985 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:45.359 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-27 11:45:45.374 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-27 11:45:45.374 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-27 11:45:45.421 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-27 11:45:45.562 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 11:45:45.578 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 11:45:45.609 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 11:45:45.624 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 11:45:45.656 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 11:45:45.656 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 11:45:45.671 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 11:45:45 CST 2017]; root of context hierarchy
2017-11-27 11:45:45.812 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-27 11:45:45.812 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-27 11:45:46.468 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.515 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.515 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.515 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.531 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.531 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.531 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.531 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.531 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.531 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.546 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.546 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.546 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.546 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.546 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.546 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.546 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.546 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.562 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.562 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.562 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.562 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.562 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.562 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.562 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.578 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.593 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.609 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.609 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.609 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.609 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.609 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.624 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.624 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.624 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.624 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.624 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.624 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.624 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.624 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.624 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.624 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.624 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.624 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.624 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.624 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.624 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.624 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.624 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.624 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.624 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.624 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.624 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.624 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.624 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.640 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.640 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.640 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.640 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.640 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.640 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.640 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.640 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.640 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.640 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.640 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.640 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.640 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 11:45:46.656 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.656 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.656 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.656 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.656 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 11:45:46.656 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 11:45:46.656 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 11:45:46.656 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 11:45:46.656 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 11:45:46.656 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 11:45:46.687 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-27 11:45:46.703 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 11:45:45 CST 2017]; root of context hierarchy
2017-11-27 11:45:46.718 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-27 11:45:48.718 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.718 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.718 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.718 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.718 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.734 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.734 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.734 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 11:45:48.749 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:39.644 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-27 12:13:39.660 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-27 12:13:39.668 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-27 12:13:39.707 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-27 12:13:39.848 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 12:13:39.863 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 12:13:39.895 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 12:13:39.895 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 12:13:39.926 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 12:13:39.942 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 12:13:39.957 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 12:13:39 CST 2017]; root of context hierarchy
2017-11-27 12:13:40.082 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-27 12:13:40.082 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-27 12:13:40.738 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.785 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.785 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.801 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.801 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.801 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.801 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.801 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.801 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.801 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.817 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.848 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.848 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.848 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.848 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.848 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.848 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.848 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.863 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.863 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.863 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.863 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.863 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.863 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.863 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.863 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.879 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.879 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.879 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.879 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.879 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.879 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.879 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.879 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.879 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.879 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.879 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.879 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.879 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.879 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.879 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.879 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.879 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.879 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.879 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.879 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.879 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.879 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.879 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.879 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.879 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.879 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.879 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.879 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.879 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.879 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.895 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.895 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.895 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.895 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.895 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.895 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.895 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.895 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.895 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.895 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.895 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.895 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.895 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.895 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.895 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.895 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.895 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.895 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.895 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.895 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.895 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.895 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.895 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.895 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.895 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.895 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.895 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.895 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.895 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.895 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.895 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.910 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.910 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.910 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.910 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.910 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.910 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.910 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.910 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.910 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.910 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.910 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.910 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.910 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:13:40.926 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.926 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.926 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.926 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.926 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:13:40.926 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:13:40.926 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:13:40.926 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:13:40.926 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:13:40.926 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:13:40.957 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-27 12:13:40.988 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 12:13:39 CST 2017]; root of context hierarchy
2017-11-27 12:13:40.988 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-27 12:13:43.466 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.466 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.482 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.498 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.498 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.498 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.498 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.498 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:13:43.498 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:05.758 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-27 12:23:05.764 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-27 12:23:05.773 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-27 12:23:05.823 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-27 12:23:05.955 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 12:23:05.973 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 12:23:06.007 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 12:23:06.018 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 12:23:06.051 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 12:23:06.060 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 12:23:06.073 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 12:23:06 CST 2017]; root of context hierarchy
2017-11-27 12:23:06.202 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-27 12:23:06.202 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-27 12:23:06.874 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.926 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.926 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.931 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.936 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.936 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.938 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.944 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.944 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.945 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.949 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.949 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.951 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.957 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.957 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.958 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.961 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.962 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.963 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.966 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.966 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.968 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.972 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.973 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.976 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.983 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.983 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.984 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.987 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.987 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.989 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.992 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.992 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.993 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:06.996 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:06.997 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:06.998 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:07.003 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:07.003 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:07.005 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:07.009 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:07.009 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:07.017 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.017 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.017 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.016 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.017 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.017 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.016 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.017 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.019 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.020 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.020 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.020 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.021 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:07.021 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.022 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.023 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.028 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.028 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.028 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.028 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.028 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.028 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.028 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.028 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.028 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.028 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.028 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.028 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.029 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.029 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.029 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.029 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.029 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.029 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.029 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.029 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.029 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.029 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.029 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.029 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.029 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.029 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.029 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.029 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.030 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.030 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.030 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.030 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.030 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.030 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.033 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.033 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:07.033 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:07.033 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.034 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.034 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.034 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.034 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.035 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.041 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.042 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.042 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.042 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.042 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:07.046 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:07.046 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:07.047 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:07.050 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.051 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.051 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.051 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.052 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:07.052 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:07.053 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:07.055 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:07.055 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:07.055 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.056 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.056 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.056 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.057 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:07.059 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:07.059 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:07.059 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.059 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.059 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.059 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.060 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 12:23:07.062 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.063 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.063 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.063 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.064 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 12:23:07.064 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 12:23:07.071 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 12:23:07.072 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 12:23:07.072 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 12:23:07.072 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 12:23:07.109 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-27 12:23:07.126 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 12:23:06 CST 2017]; root of context hierarchy
2017-11-27 12:23:07.128 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-27 12:23:10.028 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.029 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.030 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.032 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.033 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.035 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.035 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.036 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.036 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.037 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.037 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.037 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.038 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.039 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.040 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.041 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.042 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.042 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.042 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 12:23:10.043 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:31.417 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-27 14:02:31.440 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-27 14:02:31.470 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-27 14:02:31.660 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-27 14:02:32.306 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 14:02:32.351 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 14:02:32.409 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 14:02:32.430 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 14:02:32.481 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 14:02:32.502 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 14:02:32.513 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 14:02:32 CST 2017]; root of context hierarchy
2017-11-27 14:02:32.987 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-27 14:02:32.987 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-27 14:02:34.997 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.235 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.235 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.244 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.248 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.248 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.250 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.257 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.257 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.260 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.268 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.268 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.270 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.275 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.275 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.276 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.280 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.280 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.282 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.285 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.285 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.288 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.296 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.296 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.298 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.302 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.302 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.305 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.307 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.307 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.308 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.312 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.312 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.314 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.318 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.318 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.319 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.323 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.323 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.326 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.331 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.331 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.332 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.337 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.337 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.344 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.352 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.353 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.354 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.357 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.357 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.358 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.360 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.360 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.362 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.364 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.364 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.366 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:02:35.368 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:02:35.368 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:02:35.523 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-27 14:02:35.571 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 14:02:32 CST 2017]; root of context hierarchy
2017-11-27 14:02:35.573 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-27 14:02:35.579 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.580 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.581 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.583 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:02:35.583 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:02:35.582 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:02:35.586 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.586 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.582 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:02:35.587 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.589 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.590 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.590 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.591 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.591 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.591 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.592 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.592 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.592 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.593 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:35.619 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:02:35.619 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:02:35.619 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:02:35.619 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:02:35.619 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:02:35.619 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:02:35.619 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:02:35.619 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:02:35.619 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:02:35.619 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:02:35.620 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:02:35.620 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:02:38.499 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:38.500 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:38.500 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:02:38.501 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:22.755 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-27 14:27:22.846 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-27 14:27:22.894 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-27 14:27:23.148 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-27 14:27:23.790 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 14:27:23.818 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 14:27:23.880 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 14:27:23.907 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-27 14:27:23.962 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-27 14:27:23.980 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-27 14:27:23.993 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 14:27:23 CST 2017]; root of context hierarchy
2017-11-27 14:27:24.372 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-27 14:27:24.372 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-27 14:27:26.430 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.667 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.668 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.673 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.677 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.678 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.680 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.684 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.684 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.687 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.696 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.696 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.697 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.701 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.701 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.703 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.706 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.707 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.708 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.711 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.711 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.715 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.736 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.737 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.740 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.744 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.745 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.747 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.752 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.752 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.754 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.758 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.758 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.759 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.762 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.763 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.764 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.767 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.768 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.770 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.773 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.773 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.776 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.779 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.779 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.789 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.795 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.795 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.797 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.799 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.799 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.801 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.803 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.803 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.805 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.808 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.808 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.809 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-27 14:27:26.812 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-27 14:27:26.812 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-27 14:27:26.937 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.938 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.939 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.938 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.938 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.937 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.938 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.938 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.944 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.945 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.946 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.947 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.947 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.947 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.949 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.950 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.953 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.954 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.959 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.959 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-27 14:27:26.976 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.976 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.976 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.977 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.977 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.977 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.977 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.977 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.977 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.977 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.977 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.977 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.977 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.977 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.977 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.977 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.978 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.978 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.978 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.978 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.978 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.978 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.978 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.978 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.978 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.978 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.978 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.978 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.978 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.978 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.978 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.978 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.978 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.978 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.978 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.978 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.979 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.979 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.979 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.979 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.979 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.979 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.979 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.979 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.979 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.979 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.979 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.979 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.977 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.976 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.979 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.978 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.978 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.978 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-27 14:27:26.981 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.981 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-27 14:27:26.981 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.981 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.979 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:26.981 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-27 14:27:27.039 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-27 14:27:27.081 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Mon Nov 27 14:27:23 CST 2017]; root of context hierarchy
2017-11-27 14:27:27.084 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-27 14:27:29.606 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.603 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.607 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.609 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.611 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.612 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.612 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.613 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.612 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.613 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.614 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.614 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.616 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.617 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.617 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.617 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.618 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.618 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.618 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-27 14:27:29.619 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:15:59.638 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-29 15:15:59.682 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-29 15:15:59.721 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-29 15:16:00.125 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-29 15:16:00.620 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 15:16:00.650 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 15:16:00.683 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 15:16:00.695 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 15:16:00.725 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 15:16:00.740 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 15:16:00.753 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 15:16:00 CST 2017]; root of context hierarchy
2017-11-29 15:16:01.325 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-29 15:16:01.325 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-29 15:16:02.924 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.140 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.140 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.144 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.150 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.151 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.152 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.158 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.158 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.161 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.165 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.165 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.170 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.174 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.174 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.176 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.182 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.182 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.184 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.186 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.186 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.188 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.190 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.190 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.192 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.196 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.196 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.197 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.199 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.199 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.201 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.203 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.203 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.204 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.206 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.207 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.209 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.214 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.214 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.215 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.218 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.218 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.220 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.222 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.222 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.228 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.233 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.233 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.235 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.241 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.242 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.243 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.246 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.246 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.248 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.250 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.250 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.252 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 15:16:03.254 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 15:16:03.255 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 15:16:03.360 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.346 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.363 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.362 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.362 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.366 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.368 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.369 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.346 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.350 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.370 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.371 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.350 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.352 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.354 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.356 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.359 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.375 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.375 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.375 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.375 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.355 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.375 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.375 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.375 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.375 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.375 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.375 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.375 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.375 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.375 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.375 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.375 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.357 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.376 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.376 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.376 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.376 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.357 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 15:16:03.376 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.376 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.377 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.377 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.377 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.377 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.377 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.377 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.377 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.377 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.377 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.377 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.377 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.377 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.377 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.378 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.378 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.378 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.378 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.378 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.378 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.378 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.378 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.378 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.377 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.378 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.378 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.378 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.378 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.378 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.378 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 15:16:03.379 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 15:16:03.380 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.387 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.387 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.387 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.395 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.400 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.401 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.400 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.401 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.401 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.401 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.401 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.401 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.403 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.401 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.400 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.400 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.400 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.410 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.410 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.410 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.410 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.411 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.411 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.411 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.411 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.412 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.412 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.412 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.412 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.412 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.412 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.410 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.413 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.413 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.412 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 15:16:03.419 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.421 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-14-0] for group 0
2017-11-29 15:16:03.421 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-14-0]
2017-11-29 15:16:03.422 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.422 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.422 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-13-0] for group 0
2017-11-29 15:16:03.422 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-13-0]
2017-11-29 15:16:03.422 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-3-0] for group 0
2017-11-29 15:16:03.422 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-3-0]
2017-11-29 15:16:03.422 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.422 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-17-0] for group 0
2017-11-29 15:16:03.422 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-17-0]
2017-11-29 15:16:03.422 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.422 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.423 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-0-0] for group 0
2017-11-29 15:16:03.423 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-0-0]
2017-11-29 15:16:03.423 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-18-0] for group 0
2017-11-29 15:16:03.423 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-18-0]
2017-11-29 15:16:03.423 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.423 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.423 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.423 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-16-0] for group 0
2017-11-29 15:16:03.423 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-7-0] for group 0
2017-11-29 15:16:03.423 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-16-0]
2017-11-29 15:16:03.423 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-7-0]
2017-11-29 15:16:03.423 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-5-0] for group 0
2017-11-29 15:16:03.423 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-5-0]
2017-11-29 15:16:03.423 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.423 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.423 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.424 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-15-0] for group 0
2017-11-29 15:16:03.424 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-15-0]
2017-11-29 15:16:03.424 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-19-0] for group 0
2017-11-29 15:16:03.424 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-19-0]
2017-11-29 15:16:03.424 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.424 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-8-0] for group 0
2017-11-29 15:16:03.424 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-8-0]
2017-11-29 15:16:03.424 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.424 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-4-0] for group 0
2017-11-29 15:16:03.424 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-4-0]
2017-11-29 15:16:03.424 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.424 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.424 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-9-0] for group 0
2017-11-29 15:16:03.424 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-9-0]
2017-11-29 15:16:03.424 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-2-0] for group 0
2017-11-29 15:16:03.424 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-2-0]
2017-11-29 15:16:03.424 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.425 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.425 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.425 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group 0 with generation 378
2017-11-29 15:16:03.425 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-12-0] for group 0
2017-11-29 15:16:03.425 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-12-0]
2017-11-29 15:16:03.425 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-6-0] for group 0
2017-11-29 15:16:03.425 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-6-0]
2017-11-29 15:16:03.424 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-1-0] for group 0
2017-11-29 15:16:03.426 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-1-0]
2017-11-29 15:16:03.425 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-10-0] for group 0
2017-11-29 15:16:03.427 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-10-0]
2017-11-29 15:16:03.425 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [topic-11-0] for group 0
2017-11-29 15:16:03.428 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [topic-11-0]
2017-11-29 15:16:03.485 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-29 15:16:03.531 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 15:16:00 CST 2017]; root of context hierarchy
2017-11-29 15:16:03.532 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-29 15:16:03.539 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.539 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.541 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.545 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.545 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.546 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.546 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.547 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.547 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.549 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.550 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.550 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.551 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.552 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.553 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.555 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.556 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.556 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.559 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 15:16:03.560 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:04.684 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-29 16:10:04.688 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-29 16:10:04.697 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-29 16:10:04.750 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-29 16:10:04.895 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 16:10:04.914 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 16:10:04.954 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 16:10:04.969 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 16:10:05.012 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 16:10:05.026 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 16:10:05.047 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 16:10:05 CST 2017]; root of context hierarchy
2017-11-29 16:10:05.225 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-29 16:10:05.225 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-29 16:10:06.022 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.080 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.080 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.085 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.093 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.093 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.095 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.110 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.110 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.112 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.118 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.118 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.119 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.128 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.128 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.132 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.136 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.136 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.139 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.142 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.142 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.144 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.148 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.148 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.149 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.154 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.155 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.157 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.159 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.159 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.161 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.165 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.166 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.167 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.173 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.173 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.175 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.182 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.182 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.182 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.182 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.182 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.185 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.185 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.185 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.186 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.186 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.186 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.186 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.186 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.186 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.189 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.191 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.191 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.191 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.191 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.191 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.191 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.191 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.197 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.198 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.198 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.198 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.198 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.199 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.199 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.200 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.201 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.201 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.202 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.202 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.202 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.203 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.203 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.203 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.205 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.205 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.205 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.205 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.206 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.207 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.207 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.207 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.211 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.211 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.212 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.212 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.213 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.215 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.215 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.217 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.218 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.218 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.218 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.217 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.220 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.220 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.220 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.220 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.221 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.222 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.226 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.227 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.227 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.227 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.232 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.235 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.235 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.237 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.240 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.242 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.242 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.242 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.244 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.244 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.247 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.250 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.251 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.251 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.251 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.255 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.255 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.257 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.259 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.259 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.260 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:10:06.260 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.261 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.261 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.261 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.263 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.263 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:10:06.263 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:10:06.263 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.263 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.263 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.270 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:10:06.270 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:10:06.270 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:10:06.270 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:10:06.315 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-29 16:10:06.334 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 16:10:05 CST 2017]; root of context hierarchy
2017-11-29 16:10:06.338 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-29 16:10:09.175 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.177 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.181 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.183 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.184 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.186 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.189 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.190 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.190 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.193 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.194 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.194 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.195 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.195 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.196 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.196 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.197 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.199 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.199 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:10:09.200 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:15.968 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-29 16:21:15.971 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-29 16:21:15.979 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-29 16:21:16.036 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-29 16:21:16.183 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 16:21:16.201 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 16:21:16.243 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 16:21:16.258 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 16:21:16.323 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 16:21:16.334 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 16:21:16.352 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 16:21:16 CST 2017]; root of context hierarchy
2017-11-29 16:21:16.515 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-29 16:21:16.515 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-29 16:21:17.270 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.329 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.329 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.335 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.344 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.345 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.346 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.359 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.359 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.361 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.367 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.367 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.369 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.374 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.374 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.377 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.381 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.381 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.384 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.388 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.388 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.389 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.393 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.393 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.395 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.399 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.399 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.401 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.408 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.408 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.410 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.419 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.420 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.424 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.425 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.426 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.426 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.426 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.426 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.427 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.427 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.427 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.427 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.427 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.427 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.427 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.428 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.428 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.428 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.428 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.428 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.428 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.428 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.428 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.429 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.429 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.429 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.429 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.429 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.429 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.430 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.429 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.430 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.431 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.431 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.440 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.440 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.441 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.441 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.441 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.443 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.444 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.444 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.444 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.445 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.445 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.447 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.453 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.454 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.454 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.454 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.454 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.455 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.455 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.455 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.457 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.457 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.459 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.466 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.467 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.467 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.467 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.467 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.467 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.468 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.471 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.471 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.471 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.472 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.472 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.472 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.479 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.480 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.481 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.481 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.484 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.490 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.490 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.492 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.494 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.494 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.496 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.498 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.498 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.498 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.498 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.501 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.501 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.502 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.503 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.503 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.503 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.503 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.509 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.509 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.510 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:21:17.511 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.512 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.512 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.512 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.514 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.515 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.515 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.515 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.517 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:21:17.517 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:21:17.522 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:21:17.523 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:21:17.523 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:21:17.523 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:21:17.568 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-29 16:21:17.588 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 16:21:16 CST 2017]; root of context hierarchy
2017-11-29 16:21:17.591 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-29 16:21:19.811 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.813 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.822 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.832 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.833 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.833 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.834 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.834 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.835 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.835 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.835 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.835 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.836 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.836 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.838 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.838 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.839 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.839 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.840 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:21:19.840 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:12.222 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-29 16:33:12.227 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-29 16:33:12.234 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-29 16:33:12.290 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-29 16:33:12.453 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 16:33:12.471 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 16:33:12.511 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 16:33:12.529 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 16:33:12.582 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 16:33:12.599 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 16:33:12.617 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 16:33:12 CST 2017]; root of context hierarchy
2017-11-29 16:33:12.786 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-29 16:33:12.786 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-29 16:33:13.571 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.627 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.627 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.632 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.639 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.639 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.640 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.648 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.649 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.651 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.669 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.669 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.672 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.682 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.682 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.686 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.691 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.691 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.694 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.699 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.699 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.700 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.703 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.703 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.706 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.711 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.714 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.715 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.721 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.721 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.721 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.723 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.723 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.723 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.723 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.723 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.723 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.723 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.723 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.723 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.723 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.724 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.724 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.724 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.726 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.727 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.727 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.727 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.730 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.731 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.731 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.731 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.731 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.731 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.732 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.732 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.732 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.732 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.732 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.732 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.737 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.737 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.740 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.741 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.741 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.741 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.741 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.743 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.744 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.744 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.744 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.746 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.746 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.747 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.750 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.750 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.750 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.751 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.751 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.751 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.752 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.758 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.759 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.759 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.759 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.761 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.761 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.768 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.769 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.769 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.769 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.769 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.772 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.772 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.775 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.777 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.777 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.778 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.779 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.779 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.779 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.788 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.792 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.792 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.792 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.792 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.792 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.792 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.795 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.797 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.797 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.799 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.801 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.802 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.802 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.802 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.802 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.803 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.803 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.803 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.806 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.806 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.809 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.811 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.811 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.812 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.812 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:33:13.813 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.813 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.813 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.815 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.816 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.816 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.816 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:33:13.819 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:33:13.824 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:33:13.825 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:33:13.825 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:33:13.825 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:33:13.867 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-29 16:33:13.888 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 16:33:12 CST 2017]; root of context hierarchy
2017-11-29 16:33:13.890 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-29 16:33:15.465 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.477 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.478 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.481 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.483 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.484 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.484 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.485 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.486 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.486 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.486 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.486 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.487 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.488 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.489 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.490 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.490 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.491 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.491 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:33:15.491 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:06.056 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-29 16:34:06.060 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-29 16:34:06.069 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-29 16:34:06.125 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-29 16:34:06.272 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 16:34:06.289 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 16:34:06.328 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 16:34:06.350 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 16:34:06.397 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 16:34:06.413 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 16:34:06.426 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 16:34:06 CST 2017]; root of context hierarchy
2017-11-29 16:34:06.603 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-29 16:34:06.603 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-29 16:34:07.390 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.450 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.450 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.456 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.466 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.466 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.472 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.477 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.477 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.480 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.484 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.484 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.486 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.490 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.490 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.494 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.500 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.500 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.501 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.511 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.511 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.512 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.520 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.520 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.523 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.535 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.535 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.538 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.546 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.548 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.548 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.548 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.548 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.549 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.549 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.549 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.555 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.556 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.556 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.556 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.560 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.562 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.562 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.563 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.563 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.563 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.563 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.563 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.563 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.564 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.564 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.570 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.570 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.574 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.574 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.574 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.574 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.575 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.575 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.575 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.575 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.576 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.576 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.576 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.577 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.577 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.577 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.581 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.581 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.587 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.588 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.588 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.588 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.590 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.595 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.596 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.596 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.596 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.597 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.597 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.600 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.603 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.604 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.604 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.604 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.609 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.609 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.612 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.617 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.617 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.618 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.619 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.619 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.619 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.623 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.626 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.626 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.627 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.627 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.627 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.627 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.638 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.645 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.646 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.647 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.648 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.648 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.648 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.651 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.658 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.659 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.659 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.659 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.664 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.664 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.665 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.669 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.669 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.669 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.669 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.670 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.671 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.672 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.675 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.676 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.676 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.676 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.676 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.676 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.678 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 16:34:07.682 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.683 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.683 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.683 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.685 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 16:34:07.685 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 16:34:07.690 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 16:34:07.691 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 16:34:07.691 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 16:34:07.691 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 16:34:07.735 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-29 16:34:07.755 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 16:34:06 CST 2017]; root of context hierarchy
2017-11-29 16:34:07.756 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
2017-11-29 16:34:09.587 [messageListenerContainer20-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.588 [messageListenerContainer16-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.590 [messageListenerContainer10-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.596 [messageListenerContainer6-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.600 [messageListenerContainer3-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.602 [messageListenerContainer19-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.603 [messageListenerContainer-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.604 [messageListenerContainer11-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.604 [messageListenerContainer9-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.604 [messageListenerContainer12-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.605 [messageListenerContainer8-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.605 [messageListenerContainer5-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.605 [messageListenerContainer7-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.606 [messageListenerContainer14-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.606 [messageListenerContainer17-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.606 [messageListenerContainer2-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.607 [messageListenerContainer15-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.607 [messageListenerContainer18-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.608 [messageListenerContainer4-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 16:34:09.608 [messageListenerContainer13-C-1] INFO  o.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2017-11-29 17:01:11.038 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2017-11-29 17:01:11.041 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Could not instantiate TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener]. Specify custom listener classes or make the default listener classes (and their required dependencies) available. Offending class: [javax/servlet/ServletContext]
2017-11-29 17:01:11.049 [main] INFO  org.springframework.test.context.support.DefaultTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@58a90037, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@74294adb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@70a9f84e, org.springframework.test.context.transaction.TransactionalTestExecutionListener@130f889, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1188e820]
2017-11-29 17:01:11.108 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\service.xml]
2017-11-29 17:01:11.257 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 17:01:11.275 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 17:01:11.307 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 17:01:11.321 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-consumer.xml]
2017-11-29 17:01:11.364 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-dao.xml]
2017-11-29 17:01:11.375 [main] INFO  org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from file [F:\git\mavenProject\file2DB\file2DB-service\target\classes\spring\spring-producer.xml]
2017-11-29 17:01:11.392 [main] INFO  org.springframework.context.support.GenericApplicationContext - Refreshing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 17:01:11 CST 2017]; root of context hierarchy
2017-11-29 17:01:11.537 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - Skipping MapperFactoryBean with name 'extractDao' and 'org.dao.ExtractDao' mapperInterface. Bean already defined with the same name!
2017-11-29 17:01:11.537 [main] WARN  org.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[org.dao]' package. Please check your configuration.
2017-11-29 17:01:12.300 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.358 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.358 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.366 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.371 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.371 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.373 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.377 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.377 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.379 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.384 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.384 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.386 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.391 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.391 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.394 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.397 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.398 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.399 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.402 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.404 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.406 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.412 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.412 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.414 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.420 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.420 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.421 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.425 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.425 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.426 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.429 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.430 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.432 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.435 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.435 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.436 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.439 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.439 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.441 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.445 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.445 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.446 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.449 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.449 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.466 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.466 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.467 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.468 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.468 [messageListenerContainer9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.468 [messageListenerContainer9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.469 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.469 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.469 [messageListenerContainer11-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.469 [messageListenerContainer11-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.468 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.470 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.470 [messageListenerContainer14-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.470 [messageListenerContainer7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.470 [messageListenerContainer14-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.470 [messageListenerContainer7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.471 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.471 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.471 [messageListenerContainer8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.471 [messageListenerContainer8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.468 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.474 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.474 [messageListenerContainer6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.474 [messageListenerContainer6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.475 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.475 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.475 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.476 [messageListenerContainer10-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.476 [messageListenerContainer10-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.476 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.476 [messageListenerContainer12-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.476 [messageListenerContainer12-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.481 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.482 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.483 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.483 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.483 [messageListenerContainer-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.483 [messageListenerContainer2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.483 [messageListenerContainer-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.483 [messageListenerContainer2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.487 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.488 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.488 [messageListenerContainer3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.489 [messageListenerContainer3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.492 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.492 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.493 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.493 [messageListenerContainer4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.493 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.493 [messageListenerContainer4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.493 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.493 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.493 [messageListenerContainer5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.493 [messageListenerContainer5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.494 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.494 [messageListenerContainer13-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.494 [messageListenerContainer13-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.500 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.500 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.502 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.503 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.503 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.503 [messageListenerContainer15-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.503 [messageListenerContainer15-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.509 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.509 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.511 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.511 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.512 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.512 [messageListenerContainer16-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.512 [messageListenerContainer16-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.514 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.514 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.516 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.520 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.520 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.521 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.521 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.521 [messageListenerContainer18-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.521 [messageListenerContainer18-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.521 [messageListenerContainer17-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.521 [messageListenerContainer17-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.522 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.522 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.525 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.152.45:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2017-11-29 17:01:12.528 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.0
2017-11-29 17:01:12.528 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : cb8625948210849f
2017-11-29 17:01:12.533 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.533 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.533 [messageListenerContainer19-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.533 [messageListenerContainer19-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.534 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator 192.168.152.45:9092 (id: 2147483647 rack: null) for group 0.
2017-11-29 17:01:12.535 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group 0
2017-11-29 17:01:12.535 [messageListenerContainer20-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2017-11-29 17:01:12.535 [messageListenerContainer20-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group 0
2017-11-29 17:01:12.577 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2017-11-29 17:01:12.597 [Thread-1] INFO  org.springframework.context.support.GenericApplicationContext - Closing org.springframework.context.support.GenericApplicationContext@3c0a50da: startup date [Wed Nov 29 17:01:11 CST 2017]; root of context hierarchy
2017-11-29 17:01:12.599 [Thread-1] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
